[["index.html", "Chaos Game Cover", " Chaos Game 2023-01-01 Cover "],["how-to-read-this-book.html", "How to read this book?", " How to read this book? Fractals are bizarre figures. Seemingly chaotic but described in a surprisingly orderly way. However, to discover this order, one must know what to look at. Our journey through the land of fractals consists of three parts. Each part has its own guide, an outstanding Polish mathematician whose results are related to fractals. The first part is mainly focused on the construction of three simple fractals. Here we will organize some key concepts necessary to understand the succeeding chapters. A brilliant organizer — Wacław Sierpiński – is the guide. The second part will allow us to delve into the mathematical foundations of fractals. There will be definitions and theorems that math students usually encounter in their first year of study. Who could take better care of this part than the brilliant mathematician Stefan Banach? The third part is lead by Hugo Steinhaus, who was very interested in applications. So he is a dream guide to interesting applications of fractals. Each part begins with the presentation of a guide because mathematics is not only about formulas but also about the people who create it. There are legends about the three mentioned above. Therefore each part contains a short comic strip referring to an interesting event from their lives. Then a new method of fractal construction is presented. This should stimulate a mathematical appetite that can only be satisfied by a formal mathematical presentation of why the method works. The last section of each part includes examples of R, Python, and Julia programs that allow you to reproduce the fractals discussed earlier in the chapter. At the end of the book, there is a pocket atlas of fractals that interested readers can experiment with on their own. Why fractals? More than a quarter of a century ago, when I was in my second year of high school, my geometry teacher professor Wiesław Kostarczyk passed on to me a book that rekindled my interest in mathematics. It was Fractals. From Geometry to Art (Polish: Fraktale. Od geometrii do sztuki) by professor Piotr Pierański [Pier92]. I understood maybe one-fifth of the book at the time, but it was enough to get me interested in the subject for years. And every now and then, I rediscover connections with fractals in algorithmics, probability theory, topology, or functional analysis. Who knows, maybe, Dear Reader, this book will also awaken your interest in these bizarre objects. Acknowledgements This book would not have come into being thanks to the many people and institutions who helped, sometimes indirectly and sometimes directly, at various stages of the work. It is not feasible to mention them all, but I must thank at least a few people and institutions. The first version of the sample codes in Python and Julia was created thanks to Krzysztof Trajkowski, who has been supporting me in various initiatives for years. The book has been translated into English by two brilliant students Mateusz Krzyzinski and Barlomiej Sobieski (both from Data Science at MiNI WUT). The illustrations in this book were created thanks to Aleksander Zawada, an amazing artist and graphic designer, who found the time to enrich this book with a comic strips featuring the adventures of Beta and Bit. This book is one of three items realised with the support of the task ,,Comic Maths’’ in the project MatFizChemPW — raising mathematical and natural science and ICT competences in schoolchildren. The project is co-financed by the European Union from the European Social Fund under the Knowledge Education Development Programme 2014-2020. Bibliografia "],["hello-fractals.html", "Chapter 1 Hello, fractals!", " Chapter 1 Hello, fractals! The chapter in which we meet the investigator of infinity and, for the first time, draw a carpet consisting almost entirely of holes. Beta and Bit meet Waclaw Sierpinski during a lecture in Krakow In the scribblings of the bored Beat, Waclaw Sierpinski identified a very interesting figure "],["wacław-sierpiński.html", "1.1 Wacław Sierpiński", " 1.1 Wacław Sierpiński The period between the two world wars was not only the rebirth of Poland, it was also a time of very intensive development of the Polish school of mathematics. The main centers of development of this school in the interwar period were Warsaw, Lwów and Cracow. The leading mathematicians of that time often traveled between these cities, inspiring each other, exchanging knowledge and experience. And when we talk about leading mathematicians, it is impossible not to mention Wacław Sierpiński, who received his master’s degree in Warsaw, his doctorate in Cracow, and his habilitation in Lwów. Could there be a better date of birth for a mathematician than March, 14th? On this day in 1882 in Warsaw, our hero was born. He went to the Imperial University of Warsaw for his studies, where, under the supervision of Georgy Voronoy (yes, it’s that Voronoy from Voronoi diagram – a partition of a plane into n cells, defined by n seeds. Each point of the plane is assigned to the cells whose seed is closest to it), he became interested in number theory, defended his degree as a candidate of sciences (the equivalent of today’s master’s degree) and began teaching mathematics at a junior high school. He did not work there for long. As a very active person, he participated in school strikes, which caused him to lose his job. So he moved to Cracow, and at the Jagiellonian University, he quickly earned his doctorate, studying the sums of series \\(\\sum_{m^2+n^2 \\leq x}f(m^2+n^2)\\). Three years later, he had received habilitation at Lwów University. During that period and for the rest of his life, he traveled extensively to excellent mathematical centers around the world, including studying in Göttingen, where he met the mathematician Constantin Carathéodory (who worked for a time in Breslau, today’s Wrocław) and Hugo Steinhaus (about whom we write more in Chapter Three). He was a great organizer, taking part in many initiatives. For example, in 1920, he together with Zygmunt Janiszewski (a mathematician, author of, among other, Guide for the self-study, Polish: Poradnik dla samouków, introducing mathematics at the university level) and Stefan Mazurkiewicz founded Fundamenta Mathematicae – the first journal in the world devoted to mathematical logic, set theory, and their applications. The journal continues to this day and is now published by the Institute of Mathematics of the Polish Academy of Sciences. Sierpiński quickly became known as a great and very versatile mathematician. When in 1920, Jan Kowalewski (a mathematician and cryptologist, Lieutenant Colonel of the Polish Army) was forming a unit to break Soviet ciphers, he hired Wacław Sierpiński, Stefan Mazurkiewicz, and Stanisław Leśniewski (a philosopher, logician, and mathematician) to decrypt Soviet dispatches more efficiently. The team was so effective that it was later credited with a significant contribution to the success of the Polish Army during the Polish-Soviet War, including the memorable Battle of Warsaw (a decisive battle of the Polish-Soviet War). The Cipher Bureau at that time was a very innovative venture; it is enough to say that it was established 20 years before the famous Bletchley Park (Bletchley Park, also known as Station X is an estate in England located about 80 km from London. During World War II, it was home to a team of British cryptologists from the Government Code and Cypher School. They oversaw reading ciphertexts created on German Enigma machines, Lorenz machines and others). Efficient radio listening, made possible by electronics engineers from the polytechnics, combined with effective cryptographic analysis, made possible by mathematicians from the Universities of Warsaw and Lwów, gave military commanders the necessary data on the enemy troops’ plans. There were even anecdotes that the Cipher Bureau could decrypt the dispatches faster than the intended recipients. The successes of this team laid the foundations for the Cipher Bureau in Poznan, which was made famous a decade later by the Enigma breakers Marian Rejewski, Jerzy Różycki, and Henryk Zygalski – the three mathematicians and cryptologists who broke the Enigma cipher in 1932 significantly contributed to the Allies’ victory in World War II. Over the years, Wacław Sierpiński taught students in junior high schools, lectured at universities, and wrote textbooks. There were many editions of the well-known textbook on arithmetic and geometry, which he wrote together with Stefan Banach and Włodzimierz Stożek. Because of his teaching activities, he became president of the Society of High School and University Teachers (Polish: Towarzystwo Nauczycieli Szkół Średnich i Wyższych). He was also the doctoral advisor for many prominent mathematicians, like Jerzy Spława-Neyman (a mathematician and statistician, creator of the concept of a confidence interval, author of the Neyman-Pearson lemma, fundamental to the construction of statistical tests), Otto Nikodym, Kazimierz Kuratowski (a mathematician, author of many interesting results in set theory and measure theory but also author of the theorem concerning the characterization of planar graphs), or Alfred Tarski – an outstanding logician, working, for example, on formalizing the concept of truth. Sierpiński had numerous talents, but his interests were mainly related to conducting scientific research. He wrote a total of 113 papers, so it is impossible to summarize his many results briefly. His passion was studying the concept of infinity, whether in number theory, mathematical analysis, set theory, or topology. In 1915, at the age of 33, he proposed a method for constructing an interesting figure, later called the Sierpiński triangle. It is created as the result of an infinite sequence of specific operations. It is one of the most famous fractals today, although Benoit Mandelbrot (a Warsaw-born mathematician, recognized as a father of fractal geometry) introduced the concept of fractal only 60 years later, in 1975. His tombstone can be found at Powązki Cemetery in Warsaw, and it bears the inscription Investigator of infinity. "],["hello-fractals-1.html", "1.2 Hello, fractals!", " 1.2 Hello, fractals! It’s fascinating that an endless repetition of the same actions can lead to the creation of fascinating figures – fractals. Anyone can draw such a figure with some basic knowledge of programming. We will show how to construct different classes of fractals step by step. Knowledge of the basics of algebra, probability and topology will allow you to understand more precisely where these surprising figures come from. 1.2.1 Cantor dust One of the more interesting methods of constructing fractals is the method `by removal’. We take a particular shape and then remove pieces from it. What is left is a fractal, often with surprising properties. Let’s illustrate this with an example of a fractal called (Cantor dust()) after Georg Cantor, a pioneer of set theory, who described the Cantor set in 1883. Recipe for Cantor dust construction. Take a line segment of any length (but for simplicity, ours will be of length 1). Divide this line segment into three equal parts. Remove the inside of the middle part, which will give you two line segments, both of length 1/3 of the original line segment. For each resulting line segment, continue dividing by returning to step 2. For an illustration of five consecutive steps of the biting algorithm, see Figure 2. Figure 2: First 5 iterations of Cantor dust construction The above algorithm is characterized by several elements typical for fractals. First, it never ends; the whole procedure must (at least in theory) be repeated infinitely many times. Second, we are dealing with recursion. Two objects are created as the result of the third step, and then each of them is transformed again in the same way as the initial object. Proceeding in a very similar way, you can obtain many interesting figures, but let’s look at Cantor dust for a little bit longer. Let’s see what we actually obtained as a result of this procedure. Let’s check how big the object is, that is, what is its length. Initially, the line segment had a length of \\(1\\), but in the first step, we removed \\(1/3\\) of it. In the second step, we removed \\((1/3)^2\\) twice. Repeating this several times, in step \\(k\\), we removed \\(2^{k-1}\\) line segments, each of length \\((1/3)^k\\). So the length of this creation after step \\(k\\) is: \\[\\begin{equation} \\begin{split} 1 &amp;- 1/3 - 2*(1/3)^2 - ... - 2^{k-1}*(1/3)^k = \\\\ &amp; 1 - \\sum_{i=1}^k 2^{i-1}*(1/3)^i = 1 - 1/2 \\sum_{i=1}^k (2/3)^i = \\\\ &amp; 1 - \\frac 12 (2 - 2 (2/3^k)) = (2/3)^k \\xrightarrow[k\\rightarrow \\infty]{} 0 \\end{split} \\end{equation}\\] We can reach the same conclusion using a different way reasoning, namely by looking at how much is left of a segment after the \\(k\\)-th step. After the first step, we have \\(2\\) line segments of length \\(1/3\\), after the second step, we have \\(2^2\\) line segments of length \\((1/3)^2\\), and after the \\(k\\)-th step, we have \\(2^k\\) line segments of length \\((1/3)^k\\). What does this sequence converge to? \\[ \\lim_{k \\rightarrow \\infty} (2/3)^k = 0 \\] There is no doubt. The Cantor set has a length equal to 0. But clearly, it is not an empty set because it has many points. How many? It turns out that as many as the whole line segment, and therefore uncountably many. Let’s show this using a clever proof. Theorem (Cardinality of Cantor set). Cantor set is equinumerous with the interva \\([0, 1]\\). Proof: In order to count the points in the Cantor set, we must construct a representation for each point, that is, a notation that allows us to identify each point uniquely. A representation that uniquely identifies a point will be the set of decisions determining how to reach that point in the subsequent steps of the procedure that generates Cantor dust. We remember that in each step, the centers are removed from the line segments, so the point that belongs to Cantor dust will lie either in the left or the right part of the line segment. This choice (left/right) must be made in each step of the dust construction. We can write such a representation as an infinite sequence of 0/1 digits – if 0 occurs in the sequence at a position \\(k\\), the point belongs to the left subsegment, and if 1, it belongs to the right subsegment. Note the unambiguity -&gt; any point from Cantor dust can be described by an infinite sequence of 0/1 digits. At the same time, each infinite sequence of digits describes some point from Cantor set, and different sequences represent different points. How many such sequences are there? As many as in the whole line segment. Just think of these sequences as binary expansions of the numbers in the interval \\([0, 1]\\). q.e.d. So what do we have? Cantor dust has the same number of points as the line segment \\([0, 1]\\). But at the same time, it has a length of 0, although the line segment has a length of 1. How is this possible? This is one of the many puzzles hidden in the land of fractals painted with infinity. 1.2.2 Sierpiński triangle One of the best-known fractals is certainly the Sierpiński triangle, whose construction is quite similar to the method of creating Cantor dust. Recipe for Sierpiński triangle construction. Take an equilateral triangle of any size. Divide this triangle into four equilateral triangles. Remove the inside of the middle triangle, which will give you three triangles, whose side length is half as long as the side of the original triangle. For each of the three resulting triangles, continue the division by returning to step 2. For an illustration of the four consecutive steps of the biting algorithm, see Figure 3. Figure 3: The first four iterations in the construction of Sierpiński triangle. "],["but-why-does-it-work.html", "1.3 But why does it work?", " 1.3 But why does it work? It is a lovely creation. But what properties does it have? How big is its area? A quick calculation clears up any doubts. In step \\(k\\), the triangle consists of \\(3^k\\) triangles, each with side \\(1/2^k\\), that is, area \\(\\sqrt{3}/2^{2k+1}\\). The total area of what remains after step \\(k\\) is \\((3/4)^k \\cdot \\sqrt{3}/2\\). In the limit, we get: \\[ \\lim_{k \\rightarrow \\infty} (3/4)^k \\cdot \\sqrt{3}/2 = 0. \\] The Sierpiński triangle is, therefore, so hollow that it has an area equal to 0. And how long is its edge? In step \\(k\\), the edge increases by \\(3^{k-1}\\) triangles, each with side of length \\((1/2)^k\\), that is, perimeter of \\(3 \\cdot (1/2)^k\\). The total edge length in a step \\(k\\) is: \\[ \\sum_{i=1}^k 3^{k-1} \\cdot 3 \\cdot (1/2)^k = \\sum_{i=1}^k (3/2)^k. \\] The elements of this sum grow to infinity, so the whole edge of the triangle consequently explodes to infinity: \\[ \\lim_{k \\rightarrow \\infty}\\sum_{i=1}^k (3/2)^k = \\infty. \\] What is this figure? It is bounded because it fits in a triangle with side 1 but has an infinite perimeter with zero area. What dimension is it from? Probably by this point, some readers are asking themselves what fractals are. Are they just some strange images? And if so, how do you characterize them? One of the more frequently repeated definitions of fractals is the one given by Mandelbrot, which I will paraphrase: Definition (fraktal). A fractal is a set whose fractal dimension is higher than the topological dimension. As will become clear in a moment, often the fractal dimension doesn’t need to be an integer, hence the name fractal, from the French fractus and the Latin frangěre – to break, fray, fractional. But what is this topological and fractal dimension? 1.3.1 Topological dimension When we think of Euclidean spaces, the dimension is defined by the number of orthogonal directions spanning a given space. Therefore, a point has dimension 0, a line has dimension 1, a plane has dimension 2, and we all experience a three-dimensional space. We can describe specific objects in higher-dimensional spaces, there are no limitations. A mathematician can also talk excitedly about the function space, which is infinitely dimensional. Similarly, we can think about the dimensions of sets. Intuitively, the dimension of a set will be the number of orthogonal segments that fit in that set. However, one should be careful. Everything seems to be correct; a point has dimension 0, a line segment has dimension 1, a square has dimension 2, a cube has dimension 3, and so on. However, what to do with a circle? No line segment fits in it. But after all, it should have a dimension greater than 0 because it is a kind of line segment with the ends glued together. So ideally, it should also have dimension \\(1\\). Therefore, the issue is more complicated. Mathematicians have been thinking about it for a long time, and the formal definition of the dimension for sets is relatively young. The first inductive definition was proposed less than 100 years ago independently by Paul Urson and Karl Menger (1922-1923). Today we have at least a few different definitions of dimension. Those interested will find them, along with many interesting facts, in the article A few words about dimension [Nowa11] (Polish: Kilka słów o wymiarze). For further analysis, we will keep the intuitive definition – with the number of orthogonal vectors that can be embedded in the analyzed set. 1.3.2 Minkowski dimension, or fractal box-counting dimension There are also several definitions of fractal dimension but probably the most popular is Minkowski’s definition, often called box-counting dimension. It is determined for geometric objects embedded in ordinary \\(p\\)-dimensional spaces (we will practically limit ourselves only to \\(p=2\\)). To determine it, we need to count how many \\(p\\)-dimensional boxes of side \\(\\varepsilon\\) can cover the object of interest. Mandelbrot, when writing about fractal dimension, referred to the definition of the Hausdorff dimension, which is a generalization of the Minkowski dimension. In Hausdorff’s definition, instead of equal-sized boxes, we can cover the analyzed object with any family of sets with diameters converging to 0. However, this margin is too small to accurately represent and explain the Hausdorff dimension, so let’s stay with the box dimension. If \\(N(\\varepsilon)\\) is the minimum number of boxes of side \\(\\varepsilon\\) covering an object \\(F\\), then the box-counting dimension \\(d_F\\) of this object is: \\[ d_F = \\lim_{\\varepsilon \\rightarrow 0} \\frac{\\log N(\\varepsilon)}{\\log 1/\\varepsilon}. \\] In general, this boundary may not exist. In such situations, the upper and lower limits of this sequence can be considered separately. But for the objects presented in this book, the so-defined limit always converges to something. Moreover, it does not matter what size of boxes we choose. However, I show examples for boxes that `tightly’ cover parts of the figure of interest to make calculations easier. Let’s assume for now that we are interested in boxes of side \\(\\varepsilon = 2^{-k}\\). If we want to cover a square of side \\(1\\) with such boxes, we need at least \\(N(\\varepsilon) = 2^k * 2^k = 2^{2k}\\) of them.Therefore, the box-counting dimension of the square is: \\[ d_F = \\lim_{k \\rightarrow \\infty} \\frac{\\log 2^{2k}}{\\log 1/2^{-k}} = 2. \\] What about the Sierpiński triangle? Here we only need \\(N(\\varepsilon) = 3^k\\) boxes of side \\(2^{-k}\\), so the box dimension for this triangle is: \\[ d_F = \\lim_{k \\rightarrow \\infty} \\frac{\\log 3^{k}}{\\log 1/2^{-k}} = \\frac{\\log 3}{\\log 2} = 1,5849\\ldots \\] Figure 4 illustrates what an example of covering a Sierpiński triangle with boxes of sides 1/4 and 1/8 looks like. Rysunek 4: Covering the Sierpiński triangle with boxes of sides 1/4 (left panel) and 1/8 (right panel) What is the dimension of Cantor dust? This time, we have an object in one-dimensional space, so we will cover it with line segments. Suppose we have line segments of length \\(\\varepsilon = 3^{-k}\\). To cover the entire Cantor dust, we need \\(N(\\varepsilon) = 2^k\\)such segments; that is, the box dimension for Cantor dust is: \\[ d_F = \\lim_{k \\rightarrow \\infty} \\frac{\\log 2^{k}}{\\log 1/3^{-k}} = \\frac{\\log 2}{\\log 3} = 0,6309\\ldots \\] BK: It is unusual that the dimension of the Cantor set, whose all components are one-point sets (so it has a topological dimension of 0), has a box dimension sharply larger than 0 and fractionally so. 1.3.3 Sierpiński carpet We already know what fractals are characterized by. It is time to get to know more representatives of this amazing family. Another well-known example is the Sierpiński carpet. Recipe for Sierpiński carpet construction. Take a square of any size. Divide this square into nine squares. Remove the inside of the middle square; you will get eight squares with a side 1/3 of the initial square. For each of the resulting eight squares, continue the division by returning to step 2. For an illustration of the four consecutive steps of the biting algorithm, see [Figure 5]. Figure 5: The first four iterations in the construction of the Sierpiński carpet. What is the box dimension of this object? Let’s take boxes of side \\(\\varepsilon = 3^{-k}\\). To cover the carpet, we need \\(N(\\varepsilon) = 8^k\\) boxes of such size. So the box dimension of this carpet is: \\[ d_F = \\lim_{k \\rightarrow \\infty} \\frac{\\log 8^{k}}{\\log 1/3^{-k}} = \\frac{\\log 8}{\\log 3} = 1,8927... \\] Bibliografia "],["examples-in-python.html", "1.4 Examples in Python", " 1.4 Examples in Python In this chapter, we present code examples in Python to draw successive approximations of the Cantor’s Dust, the Sierpinski Triangle and the Sierpinski Carpet. Anyone can reproduce the described fractals on their own computer. For this purpose, you can install a Python programming language interpreter. The codes that generate fractals are short, and their understanding is possible without any prior knowledge of this language, although, of course, it is worth knowing this language. Here is some information to help you understand the codes: The following examples use the matplotlib library, which includes functions for drawing, such as the plot() function for drawing a segment and fill() for drawing filled polygons, here a triangle and a square. The figure() function creates a blank graph, and show() displays it on the screen. More complex math functions can be found in the math library. We will use the square root function sqrt() in these examples. The numpy library contains functions for operations on vectors and matrices. We will use it to simplify the notation of operations on two-element vectors – points coordinates. In many places, we use recursion, that is, the situation when a function calls itself. New functions are defined using the keyword def. One of the arguments of the presented recursive functions is depth – it specifies how many times the function should call itself recursively. 1.4.1 Cantor dust We will base the drawing of Cantor dust on the recursive function dust, which takes three arguments: x – the location from which to draw the fractal, scale – the size of the fractal, and depth – the current nesting level of the fractal. # Required libraries. import matplotlib.pyplot as plt import numpy as np # If depth=1, then we draw a line segment; # if depth&gt;1, then we draw two small copies of Cantor dust side by side. def dust(x, scale, depth): if depth &gt; 1: dust(x, scale / 3, depth - 1) dust(x + scale*2/3, scale / 3, depth - 1) else: plt.plot([x, x+scale], [0,0], color = &quot;black&quot;) # Initialize drawing and draw dust with depth of 5. plt.figure() dust(0, scale = 1, depth = 5) plt.show() The result of executing the following instructions 1.4.2 Sierpiński triangle It’s time for the iconic triangle. To draw it, we will use the recursive function sierpinski, which takes three arguments: x – the location from which to draw the fractal, scale – information about the size of the fractal, and depth – the current nesting level of the fractal. import matplotlib.pyplot as plt import numpy as np import math # We define a function that draws a triangle at point x and of side scale. def triangle(x, scale): plt.fill([x[0], x[0]+scale, x[0]+scale/2], [x[1], x[1], x[1]+scale*np.sqrt(3)/2], color = &quot;black&quot;) # Recursive function to draw Sierpiński triangle. # If depth=1, we draw a regular triangle, # if depth&gt;1, we draw three triangles side by side. def sierpinski(x, scale, depth): if depth &gt; 1: sierpinski(x, scale/2, depth-1) sierpinski(np.add(x, [scale/2, 0]), scale/2, depth-1) sierpinski(np.add(x,[scale/4,scale*np.sqrt(3)/4]), scale/2, depth-1) else: triangle(x, scale) # Initialize the figure and draw a triangle with a depth of 4. plt.figure() sierpinski([0,0], scale = 1, depth = 4) plt.show() The result of executing the following instructions 1.4.3 Sierpiński carpet The fractal structure proposed by Wacław Sierpiński can be repeated for other shapes, such as a square or pentagon. Below is an example for a square with a hole, that is Sierpiński carpet. import matplotlib.pyplot as plt import numpy as np # Recursive function to draw Sierpiński carpet. # If depth=1, we draw a square using the square() function, # if depth&gt;1, we draw eight fractals side by side. def square(x, scale): plt.fill(np.add(x[0], [0, scale, scale, 0]), np.add(x[1], [0 0, scale,scale]), color=&quot;black&quot;) def carpet(x, scale, depth): if depth &gt; 1: carpet(x, scale/3, depth-1) carpet(np.add(x, [scale/3,0]), scale/3,depth-1) carpet(np.add(x, [2*scale/3,0]), scale/3,depth-1) carpet(np.add(x, [0,scale/3]), scale/3,depth-1) carpet(np.add(x, [2*scale/3,scale/3]), scale/3,depth-1) carpet(np.add(x, [0,2*scale/3]), scale/3,depth-1) carpet(np.add(x, [scale/3,2*scale/3]), scale/3,depth-1) carpet(np.add(x, [2*scale/3,2*scale/3]), scale/3,depth-1) else: square(x, scale) plt.figure() carpet([0,0], scale = 1, depth = 4) plt.show() The result of executing the following instructions "],["examples-in-r.html", "1.5 Examples in R", " 1.5 Examples in R Dear Reader, you can reproduce the described fractals on your computer. All you need is an installed R language interpreter, which can be freely downloaded and installed from CRAN. No prior knowledge of this language is necessary, although it would, of course, be helpful. Here is some information to help you understand this code. The following examples use the basic graphics library for R, namely graphics. You don’t need to load it, as it is available immediately after starting R. The plot.new() function creates an empty graph. It is filled by using the polygon() function to draw filled polygons, here, a triangle and a square. R is a language for mathematicians and statisticians, so most of the mathematical operations are available as soon as you start the console, like the sqrt() function needed to calculate the height of an equilateral triangle. The R works natively on vectors, which means we can use arithmetic operators such as + or / for both numbers and vectors. To make the code more readable, we use recursion, a situation in which a function calls itself. New functions are defined using the function keyword. The functions shown have a depth argument, specifying how many more times the function should call itself. 1.5.1 Cantor dust Let’s start drawing fractals with Cantor dust. For this, we will use the recursive function dust, which takes four arguments: x, y – the location from which to draw the fractal, scale – information about the size of the fractal, and depth – the current nesting level of the fractal. # Recursive function to draw dust. # If depth=1, it draws a line segment, # if depth&gt;1 it draws two copies of Cantor dust side by side. dust = function(x, y, scale, depth = 1) { if (depth == 0) { lines(c(x, x + scale), c(y, y)) } else { dust(x, y, scale/3, depth - 1) dust(x + scale*2/3, y, scale/3, depth - 1) } } # Clear the screen and start drawing dust. plot.new() dust(0, 0, scale = 1, depth = 4) The result of executing the following instructions 1.5.2 Sierpiński triangle It’s time for the iconic Sierpiński triangle. To draw it, we will use the recursive function sierpinski(), which takes four arguments: x, y – the location from which to draw the fractal, scale – information about the size of the fractal, and depth depth – the current nesting level of the fractal. triangle &lt;- function(x, y, scale) { polygon(x + scale*c(0, 1, 1/2), y + scale*c(0, 0, sqrt(3)/2), col = &quot;black&quot;) } # Recursive function to draw Sierpiński triangle. # If depth=1, we draw a triangle using the triangle() function, # if depth&gt;1, we draw three triangles side by side. sierpinski &lt;- function(x, y, scale, depth = 1) { if (depth == 0) { triangle(x, y, scale) } else { sierpinski(x, y, scale/2, depth-1) sierpinski(x+scale/2, y, scale/2, depth-1) sierpinski(x+scale/4, y+sqrt(3)*scale/4,scale/2,depth-1) } } plot.new() sierpinski(0, 0, scale = 1, depth = 6) The result of executing the following instructions 1.5.3 Sierpiński carpet The fractal structure proposed by Wacław Sierpiński can be repeated for other shapes. # Recursive function to draw a carpet. # Depending on the current depth, it either draws a square or, recursively calls itself eight times. carpet = function(x, y, scale, depth = 1) { if (depth == 1) { rect(x, y, x + scale, y + scale, col = &quot;black&quot;) } else { carpet(x, y, scale/3, depth - 1) carpet(x+scale*1/3, y, scale/3, depth - 1) carpet(x+scale*2/3, y, scale/3, depth - 1) carpet(x, y+scale*1/3, scale/3, depth - 1) carpet(x+scale*2/3, y+scale*1/3, scale/3, depth - 1) carpet(x, y+scale*2/3, scale/3, depth - 1) carpet(x+scale*1/3, y+scale*2/3, scale/3, depth - 1) carpet(x+scale*2/3, y+scale*2/3, scale/3, depth - 1) } } plot.new() carpet(0, 0, scale = 1, depth = 4) The result of executing the following instructions} "],["examples-in-julia.html", "1.6 Examples in Julia", " 1.6 Examples in Julia When creating fractals, certain operations must be repeated infinitely many times, or at least for a very long time. Efficient, flexible, and very very fast programming languages are great for this. Julia is such a language. It can be downloaded from https://julialang.org/. Here is some information to help you understand the following examples. The following examples use the Plots library, a basic library for the Julia language. The plot() function from this library creates an empty graph. You can add more figures to it with the plot!() function. In the examples below, we will create additional filled polygons, triangles, and squares in this way. Julia is a language very friendly to mathematical operations, you can use mathematical functions such as sqrt() without additional modules. Arithmetic operators such as + or / work for both numbers and vectors. To make the code more readable, we use recursion, that is, a construction in which a function calls itself. New functions are defined using the word function. You can use a simplified definition with the = operator for shorter functions. We will use the shorter way when defining functions line, triangle, square. 1.6.1 Cantor dust Let’s start drawing fractals with Cantor dust. For this, we will use the recursive function dust, which takes three arguments: x – the beginning of the fractal, scale -- the size of the fractal, anddepth` – the current nesting level of the fractal. # Package with graphics functions. using Plots # Function that defines a line segment. line(x, scale) = Shape([x, x+scale], [0, 0]) # Rekurencyjna funkcja do rysowania kurzu. # Recursive function to draw dust. # If depth=1, it draws a line segment, # if depth&gt;1 it draws two copies of Cantor dust side by side. function dust(x, scale, depth=1) if depth == 0 plot!(line(x, scale), color=:black, legend=:false) else dust(x, scale/3, depth - 1) dust(x + scale*2/3, scale/3, depth-1) end end # Clear the screen and start drawing dust. plot(0, xlim=(-0.1,1.1), ylim=(-0.1,0.1), axis=nothing) dust(0.0, 1.0, 4) The result of executing the following instructions 1.6.2 Sierpiński triangle It’s time for the iconic Sierpiński triangle. To draw it, we will use the recursive function sierpinski(), which takes four arguments: x, y – the location from which to draw the fractal, scale – the size of the fractal, and depth depth – the current nesting level of the fractal. triangle(x, y, scale) = Shape([x, x+scale, x+scale/2, x], [y, y, y+scale*sqrt(3)/2, y]) # Recursive function to draw a Sierpiński triangle. # If depth=1, we draw a triangle using the triangle() function, # if depth&gt;1, we draw three Sierpiński triangles. function sierpinski(x, y, scale, depth=1) if depth==0 plot!(triangle(x,y,scale),color=:black,legend=:false) else sierpinski(x, y, scale/2, depth-1) sierpinski(x+scale/2, y, scale/2, depth-1) sierpinski(x+scale/4,y+sqrt(3)*scale/4,scale/2,depth-1) end end plot(0, xlim=(0,1), ylim=(0,1), axis=nothing) sierpinski(0, 0, 1, 6) The result of executing the following instructions 1.6.3 Sierpiński carpet The fractal structure proposed by Wacław Sierpiński can be repeated for other shapes. square(x, y, w) = Shape([x, x+w, x+w, x], [y, y, y+w, y+w]) # We use the square function defined above to draw a square. function carpet(x, y, scale, depth=1) if depth==0 plot!(square(x,y,scale), color=:black, legend=:false) else carpet(x, y, scale/3, depth-1) carpet(x, y+scale, scale/3, depth-1) carpet(x, y+2scale, scale/3, depth-1) carpet(x+scale, y, scale/3, depth-1) carpet(x+scale, y+2scale, scale/3, depth-1) carpet(x+2scale, y, scale/3, depth-1) carpet(x+2scale, y+scale, scale/3, depth-1) carpet(x+2scale, y+2scale, scale/3, depth-1) end end plot(0, xlim=(0,3), ylim=(0,3), axis=nothing) carpet(0.0, 0.0, 1.0, 5) The result of executing the following instructions "],["fractal-that-is-fixed-point.html", "Chapter 2 Fractal, that is fixed point", " Chapter 2 Fractal, that is fixed point The chapter in which we learn what contraction is, as well as learn about many mathematical objects. Beta and Bit meet Stefan Banach at the Scottish Cafe in Lwów Stefan Banach finds an interesting theorem in the whining of the bored Bit "],["stefan-banach.html", "2.1 Stefan Banach", " 2.1 Stefan Banach In 1892, one of the most outstanding mathematicians of the 20th century, a brilliant self-taught scientist, a man of legend - Stefan Banach - was born in Krakow. He was interested in mathematics already in junior high school but treated it rather as a hobby. A series of coincidences determined him to become a leading representative of the Lwów school of mathematics. In high school, Banach became friends with his schoolmate Witold Wilkosz (a mathematician, physicist, philosopher, and prominent popularizer of science), later a professor of mathematics at Jagiellonian University, with whom he discussed various mathematical puzzles. Later, Otto Nikodym joined this group of mathematical enthusiasts, and it was one of the conversations about mathematics between Banach and Nikodym that led to his meeting with Hugo Steinhaus. Steinhaus recognized the young Banach’s immense mathematical talent and created the conditions that quickly led to the development of one of the most creative, original mathematical minds. In 1920, thanks to the efforts of Hugo Steinhaus, Banach obtained a position as an assistant at the Lwów Polytechnic under Antoni Łomnicki (a mathematician mainly associated with the Lwów Polytechnic, where he was a professor, head of the Department of Mathematics, dean, and pro-rector). Mathematical talent and hard work soon paid off. In his doctoral thesis, Banach included new, currently fundamental theorems of the emerging discipline of mathematics - functional analysis. One of the results was the definition of a `B-space,’ which today is called a Banach space. A Banach space is a linear, normed space in which the metric determined by the norm is complete. The definition of these properties is beyond the scope of this book, but we will write something more about linearity and completeness in this chapter. There are many anecdotes about Banach’s life. One of them concerns obtaining a doctoral degree. According to the story, Banach did not care about academic titles so much that he did not even intend to seek a doctorate. Seeing the mathematician’s talent and believing that a doctoral degree was necessary, his superiors hatched an intrigue. They assembled his dissertation from loose notes with theorems and dragged him to the doctoral exam by trickery, saying that a delegation from Warsaw had come with some interesting mathematical problems, and the solutions needed to be explained to them. In reality, Banach graduated with a standard doctorate, but his dismissive attitude toward titles was fodder for anecdotes. Such a brilliant mind attracted other brilliant minds. Back in 1919, Banach co-founded the Mathematical Society in Kraków, which later became the Polish Mathematical Society, and still exists today. Back in Lwów, he and Steinhaus started the Lwów school of mathematics, which specialized in functional analysis. It was a talent forge, enough to name a few of its representatives: Stanisław Ulam (a co-inventor of the thermonuclear bomb and the Monte Carlo algorithm), Władysław Orlicz (a mathematician, a researcher on function spaces), Mark Kac (a mathematician, probabilist) or Stanisław Mazur (a mathematician developing theories of topological linear spaces). Stefan Banach’s favorite workplace was the Scottish Café (Polish: Kawiarnia Szkocka), where he would meet with other mathematicians over coffee, cognac, or music to work on problems that fascinated them. These problems were initially written down on napkins or a table until Łucja, Banach’s wife, equipped the group with a thick notebook. This notebook was the legendary Scottish Book – the notebook in which Lwów mathematicians wrote down mathematical problems to solve. Solving more difficult problems was rewarded with prizes. The prizes were as original as the Lwów school as a whole. Suffice it to say that one of them was a live goose. To this day, not all problems have been solved. Banach’s name is found in many mathematical theorems or other amazing results. One of them is the Banach-Tarski paradox, a theorem stating that a three-dimensional ball can be cut into a finite number of parts from which two ball of the same size can be assembled after appropriate rotation and translation. An amazingly ingenious construction, seemingly impossible. How to double the volume of a ball with rotations? It turns out that it is enough to make the subsets unmeasurable, and you can already do mathematical miracles with them. Banach’s life is full of amazing twists and turns. Before World War II, he was a respected professor of mathematics. One day John von Neumann came to Lwów to bring Banach to the United States. He was to hand Banach a check with the number 1 written on it and declare that he could add as many zeros as he saw fit. To this, Banach was to reply that that’s not enough to leave Poland. But the war deprived him and many other researchers of the possibility of gainful employment. He spent part of the war as a lice feeder at the Typhus Research Institute under Professor Rudolf Weigl – a Polish biologist, inventor of the world’s first effective vaccine against spotted fever. It is estimated that he saved more than 5,000 people during the war. This was not a dream job, although it was precious because it allowed him to avoid some of the repression used by the occupiers. Steinhaus once said of Banach that he combined a spark of genius with an inner compulsion that incessantly reminded him of the words of the poet &lt;&gt; – and mathematicians know that their craft and that of the poets share the same mystery… "],["fractal-that-is-fixed-point-1.html", "2.2 Fractal, that is fixed point", " 2.2 Fractal, that is fixed point The highlight of this chapter will be the Banach fixed-point theorem and the relation of this theorem to fractals. We will start by showing the construction of some new exciting figures, such as Heighway dragon and Barnsley fern. Having satisfied the first curiosity, we will delve into the mathematical basis of these figures. For those who have studied mathematics, this can be a reminder of some concepts from mathematical analysis or topology. For those who have not studied mathematics, it may be an interesting look at how mathematicians formulate theorems. 2.2.1 Dragons and ferns The first chapter left us with a method for constructing three fractals. Each of them could be made by repeating the steps over and over again: Algorithm for constructing simple fractals. Take a shape. Copy it \\(x\\) times Scale it down by a factor of \\(y\\). Move the scaled copies around. Go back to step 2. For Cantor dust, we copied \\(x=2\\) times and scaled down by a factor of \\(y=3\\) . For the Sierpiński triangle, we copied \\(x=3\\) times, and scaled down by a factor of \\(y=2\\) . For the Sierpiński carpet, we copied \\(x=8\\) times, and scaled down by a factor of \\(y=3\\). It turns out that other different fractals can be created in a very similar way. And if we still allow rotations in addition to scaling and sliding, we get a very rich class of interesting figures. The combination of scaling, sliding, and rotation is such an important operation that it got its own name: affine transformation. An affine transformation turns line segments into line segments, straight lines into straight lines, and parallel lines into parallel lines. We will define it more formally in a few pages In step 1 of the above algorithm, we choose any shape. But the more times we repeat step 3 of this algorithm, the smaller the selected figures become. In fact, the choice of this figure doesn’t matter, we might as well draw a triangle or an elephant or a small dot at the beginning. How is this possible? This will be the main conclusion of Banach fixed-point theorem. Let’s take a drawing of elephant. After six iterations, the elephant gets the size of a grain of sand anyway. But first, let’s get to know three new fractals. 2.2.2 Sierpiński pentagon We can repeat the trick with a triangle or square with any regular polygon, such as a pentagon. Let’s copy the initial figure five times, then scale these copies down by a factor of \\(\\frac{3-\\sqrt 5}2 \\approx 0.382\\), and then shift them to the corners of the pentagon so that the scaled figures meet the vertices. After repeating this procedure many times, we will obtain a figure called the Sierpiński pentagon. Sierpiński pentagon. The result of copying the input figure five times, scaling, and shifting these copies. Each of the five copies is marked with a different color. But the real magic begins when we allow rotations in these transformations. Consider the following algorithm. Algorithm for the construction of complex fractals. Take any shape. Copy it \\(x\\) times. Scale it down by a factor of \\(y\\). Rotate and/or shift the scaled copies. Go to step 2. Let’s see how this algorithm works using a few interesting sets of transformations as an example. 2.2.3 Pythagoras tree The construction of this fractal was described in 1942 by Albert Bosman. There are several different methods of constructing this figure. Below is a construction based on two transformations. Transformation 1: rotate the figure by \\(45^{\\circ}\\) counterclockwise, then scale it by a factor of \\(1/\\sqrt{2}\\). Transformation 2: rotate the figure by \\(45^{\\circ}\\) clockwise, and then scale it by a factor of \\(1/\\sqrt{2}\\). The image below illustrates the fractal and shows the self-similarity resulting from composing transformations. The code to reproduce this fractal can be found at the end of the chapter. Panel A shows a Pythagoras tree, and panel B illustrates the two transformations that make up the fractal. The image is scaled down by a factor of \\(\\sqrt{2}\\) and rotated by 45 degrees. Each of the two replications is marked with a different color. 2.2.4 Heighway Dragon It turns out that a lot of interesting figures can be obtained using only two transformations. One such figure is the Heighway dragon, whose construction was first shown by NASA physicists John Heighway, Bruce Banks, and William Harter. The dragon is based on two transformations: Transformation 1: rotate the figure by \\(45^{\\circ}\\) counterclockwise, then scale it by a factor of \\(1/\\sqrt 2\\). Transformation 2: rotate the figure by \\(45^{\\circ}\\) counterclockwise, then scale it by a factor of \\(1/\\sqrt 2\\), and shift it by 1 along the horizontal axis. The image below illustrates the dragon and both transformations. The code to reproduce this fractal can be found at the end of the chapter. Panel A shows the Heighway dragon, and panel B illustrates the two transformations that make up the fractal. Each of the two replications is marked with a different color. 2.2.5 Barnsley fern You can achieve a lot with two transformations, but what happens when you add more? Let’s see with the example of one of the most famous fractals – Barnsley fern. It was first described in 1993 by British mathematician Michael Barnsley, who studied fractals for their potential in fractal compression. For ferns, we will need four transformations: Transformation 1 (left leaf): rotate the figure by \\(10^{\\circ}\\) counterclockwise, then scale it by a factor of \\((0.5; 0.3)\\). Transformation 2 (right leaf): rotate the figure by\\(15^{\\circ}\\) clockwise, then scale it by a factor of \\((0.45; 0.25)\\). Transformation 3 (top): rotate the figure by \\(1^{\\circ}\\) clockwise, then scale it by a factor of \\(0.9\\), and shift it by \\(0.01\\) along the X axis. Transformation 4 (stem): scale the figure by a factor of \\((0.25, 0)\\). The image below illustrates a fern and all four transformations. The code to reproduce this fractal can be found at the end of the chapter. Panel A shows a Barnsley fern, and panel B illustrates the four transformations that make up the fractal. Each of the four replications is marked with a different color. "],["but-why-does-it-work-1.html", "2.3 But why does it work?", " 2.3 But why does it work? The figures shown have a very interesting mathematical description. We present it below at the level of detail of the first years of mathematical studies. First, we will define some necessary concepts, based on which we can present the fixed-point theorem. Usually, when thinking about figures and distances, we focus on a very classic plane with two axes and the common Euclidean distance. But for the upcoming theorem, we need to look at some ideas a bit more abstractly. 2.3.1 Metric space In our story, distances between points will play a critical role. Therefore, in the rest of this chapter, we will often write about metric spaces. What are they? Definition (metric space). A metric space is a set \\(X\\) with a metric (notion of distance) \\(d\\) between the points in that set. In other words, if we work with the metric space, then for each pair of points \\(a\\) i \\(b\\), we can determine distance \\(d(a,b)\\) between them. Definition (distance). Distance is a function \\(d(a,b)\\) o defined for every two points \\(a, b \\in X\\), which satisfies the three following conditions simultaneously: \\(d(a,b) = 0 \\Leftrightarrow a = b\\), the distance is zero if and only if the points are equal to each other, \\(d(a,b) = d(b,a)\\), the distance is symmetric, \\(d(a,b) \\leq d(a,c) + d(c,b)\\), the triangle inequality, that is, the distance between any two points is always less than or equal to the sum of the distances of these points from any other point \\(c\\). Most of us in everyday life operate in Euclidean space, with ordinary `ruler’ distances. But to work with fractals, we need more sophisticated rulers. 2.3.2 Hausdorff distance In the world of fractals, the distance between points is measured very strangely – using the Hausdorff distance. Felix Hausdorff was a German mathematician born in Breslau in 1868. He died in Bonn in 1942. His main areas of interest were set theory and topology. This distance determines how far apart two figures are (in the sense of sets of points). We have two sets of points, \\(A\\) and \\(B\\), in a metric space with a metric \\(d\\), and we want to determine how far apart these sets are. The intuition behind this metric is that the sets are close to each other if, for every point from one set, some point from the other set can be found which is close to it. If every point from set \\(A\\) has such a `friend’ from set \\(B\\), then sets \\(A\\) and \\(B\\) are close. Let’s write it down more formally. Definition (Hausdorff distance). Hausdorff distance between two non-empty sets A and B is defined as: \\[ d_H(A, B) = \\max \\left\\{ \\sup_{a\\in A} \\inf_{b\\in B} d(a, b); \\sup_{b \\in B} \\inf_{a \\in A} d(a, b) \\right\\}. \\] Technically, Hausdorff distance is defined for non-empty compact sets. It can also be used for closed sets, but then it can take infinite values. We will work on compact sets, but you don’t have to say it out loud, and probably not many people will notice the difference. Illustration of Hausdorff distance The notation may frighten you, but if you break it down into parts, you will find it very intuitive. Part \\(\\inf_{b\\in B} d(a, b)\\) means the smallest distance from point \\(a\\) to any point from set \\(B\\). Likewise, \\(\\sup_{a\\in A} \\inf_{b\\in B} d(a, b)\\) is the distance of the most distant point from set \\(A\\). The distance must be symmetric, so in the formula \\(d_H(A, B)\\), we take the maximum from the value calculated in this way for set \\(A\\) with respect to set \\(B\\) and vice versa. 2.3.3 Cauchy sequence Dear Reader, as you may have already noticed, when constructing fractals, we repeat specific steps over and over again. There is a suggestion here and there that this should be done infinitely many times. However, playing around with infinity is risky, especially if we don’t have guarantees that our calculations will converge somewhere. Where to find those guarantees? Definition (Cauchy sequence). Cauchy sequence is a sequence of points \\(a_n\\), such that for any number \\(\\varepsilon\\) greater than zero, one can find such an element \\(a_N\\) in the sequence that the distance between all subsequent elements is less than \\(\\varepsilon\\). \\[ \\forall_{\\varepsilon &gt;0} \\exists_N \\forall_{m,n&gt;N} d(a_m,a_n) \\leq \\varepsilon. \\] 2.3.4 Complete space Convergent sequences satisfy the Cauchy condition, but there are spaces in which Cauchy sequences do not converge. These are not decent spaces, so we will continue to operate only on decent spaces, i.e., complete spaces. Definition (complete space). A metric space \\((X,d)\\) is complete if every Cauchy sequence \\(a_n \\subset X\\) converges in \\(X\\). And these are the guarantees of `decency’ that we need. 2.3.5 Contraction We have a decent space, now let’s talk about transformations. To construct fractals, we can use specific transformations that bring points together. We’ll call them contraction mappings, or contractions for short. Definition (contraction). A transformation \\(T\\) is a contraction mapping (contraction) if there is a constant \\(\\lambda &lt; 1\\) such that \\[ \\forall_{x,y} d(T(x), T(y)) \\leq \\lambda d(x,y). \\] That is, for any two points, \\(x\\) i \\(y\\), after the transformation, they are closer than before. In the examples discussed at the beginning of the chapter, every transformation shown was a contraction. Why? The transformations consisted of rotations, shifting, and scaling. Rotation and shifting do not change the distance between points. And all scaling was done by a factor of less than 1 for each axis. 2.3.6 Affine transformation Contractions are a very broad class of transformations. We restrict ourselves to a much narrower class of linear transformations with shifts - so-called affine transformations. An affine transformation is a composition of scaling, rotating, and shifting. If scaling reduces the figure, such an affine transformation is a contraction since rotation and shifting do not change the distance. Affine transformations can be easily described in algebraic form as the multiplication of a point by a transformation matrix. This will allow us to shorten the notation of the code that generates the fractal: \\[ T_{rotate, \\alpha}(x) = \\begin{bmatrix} \\cos(\\alpha) &amp; -\\sin(\\alpha) \\\\ \\sin(\\alpha) &amp; \\cos(\\alpha) \\end{bmatrix} x, \\] \\[ T_{scale, a, b}(x) = \\begin{bmatrix} a &amp; 0 \\\\ 0 &amp; b \\end{bmatrix} x, \\] \\[ T_{shift, a, b}(x) = x + \\begin{bmatrix} a \\\\ b \\end{bmatrix}. \\] 2.3.7 Hutchinson’s theorem At this point someone will say: “OK, each of the transformations is a contraction, but must their composition also be a contraction?”. When constructing the Sierpiński triangle, we admittedly reduced the figure, but then copied it three times. It turns out that the sum of contractions is also a contraction - and this is exactly what Hutchinson’s theorem says. Hutchinson’s theorem. A transformation \\(T = T_1 \\cup T_2 \\cup ... \\cup T_k\\) is a contraction if all transformations \\(T_1, ..., T_k\\) used to define the transformation \\(T\\) are contractions. The proof of this claim is not long, it can be found, for example, in Delta of July 2011 [Kici11]. 2.3.8 Banach’s fixed point theorem We already have everything we needed to show Banach’s fixed point theorem, that is, a decent space with a decent distance, in which we use the operator \\(T\\), which is a contraction. More precisely: Banach’s fixed point theorem. If \\((X, d)\\) is a complete metric space, and \\(T: X\\to X\\) is a contraction, then \\(T\\) has exactly one fixed point \\(x\\in X\\). The fixed point of the transformation \\(T\\) is \\(x\\) such that \\(T(x) = x\\). Banach presented the proof of this theorem in his doctoral thesis. It is not very complicated and can be found, for example, in Delta of July 2011 [Kici11]. Here we will limit ourselves only to showing how to look for this fixed point. Well, it turns out that for any point \\(x\\) przestrzeni \\(X\\) the sequence \\(T^n(x)\\) converges to a fixed point, where \\(T^n(x)\\) denotes the \\(n\\)-folded composition of the transformation \\(T\\), that is, \\(T(T(T(...T(x)...)))\\). Thus, it is enough to infinitely compose the contractions to find their fixed point. And such a fixed point are the fractals we construct… Bibliografia "],["examples-in-python-1.html", "2.4 Examples in Python", " 2.4 Examples in Python The examples presented in this chapter repeat the assembly of three atomic transformations – shift, rescale and rotate. Below are the definitions of these three transformations. In the examples below, x is a two-element vector. import numpy as np import matplotlib.pyplot as plt # Move point x by vector delta. def shift(x, delta): return np.add(x, delta) # Scale coordinates of point x by ratio. def scale(x, ratio): return np.multiply(x, ratio) # Rotate by angle of alpha (in degrees). def rotate(x, alpha): adeg = math.pi * alpha / 180 rotation_matrix = [ [np.cos(adeg), -np.sin(adeg)], [np.sin(adeg), np.cos(adeg)]] return np.matmul(x, rotation_matrix) 2.4.1 Sierpiński triangle As we wrote at the beginning of this chapter, fractals can be built from ordinary dots, we do not need more sophisticated polygons. Let’s introduce this on the basis of the Sierpiński triangle. \\[ y_1 = x * \\left[\\begin{smallmatrix} 0.5 &amp; 0\\\\ 0 &amp; 0.5 \\end{smallmatrix}\\right] \\] \\[ y_2 = x * \\left[\\begin{smallmatrix} 0.5 &amp; 0\\\\ 0 &amp; 0.5 \\end{smallmatrix}\\right] + \\left[\\begin{smallmatrix} 0.5 \\\\ 0 \\end{smallmatrix}\\right] \\] \\[ y_3 = x * \\left[\\begin{smallmatrix} 0.5 &amp; 0\\\\ 0 &amp; 0.5 \\end{smallmatrix}\\right] + \\left[\\begin{smallmatrix} 0.25 \\\\ \\sqrt3/4 \\end{smallmatrix}\\right] \\] The following program repeats the composition of these depth functions many times. In theory we would do this indefinitely, but it only takes a few steps to get a clear picture. The number of points grows exponentially, so after \\(k\\) steps it’s equal to \\(3^k\\). import matplotlib.pyplot as plt import numpy as np # Move point x by vector delta. def shift(x, delta): return np.add(x, delta) # Scale coordinates of point x by ratio. def scale(x, ratio): return np.multiply(x, ratio) def sierpinski(x, depth): if depth &gt; 1: x1 = scale(shift(x, [0, 0]), [0.5, 0.5]) sierpinski(x1, depth - 1) x2 = scale(shift(x, [0.5, 0]), [0.5, 0.5]) sierpinski(x2, depth - 1) x3 = scale(shift(x, [0.25, 0.5]), [0.5, 0.5]) sierpinski(x3, depth - 1) else: plt.plot(x[0], x[1], marker=&#39;o&#39;, color=&quot;black&quot;, markersize=3) # Initialize the drawing and draw the Sierpiński triangle. plt.figure() sierpinski([0,0], depth = 7) plt.show() The result of executing the above instructions 2.4.2 Sierpiński pentagon import math import numpy as np import matplotlib.pyplot as plt # Move point x by vector delta. def shift(x, delta): return np.add(x, delta) # Scale coordinates of point x by ratio. def scale(x, ratio): return np.multiply(x, ratio) def pentagon(x, depth, col=&quot;black&quot;): if depth &gt; 1: x1 = shift(scale(x, [0.382,0.382]), [0,0]) pentagon(x1, depth-1, col=&quot;red&quot;) x2 = shift(scale(x, [0.382,0.382]), [0.618,0]) pentagon(x2, depth-1, col=&quot;blue&quot;) x3 = shift(scale(x, [0.382,0.382]), [0.809,0.588]) pentagon(x3, depth-1, col=&quot;green&quot;) x4 = shift(scale(x, [0.382,0.382]), [0.309,0.951]) pentagon(x4, depth-1, col=&quot;orange&quot;) x5 = shift(scale(x, [0.382,0.382]), [-0.191,0.588]) pentagon(x5, depth-1, col=&quot;brown&quot;) else: plt.plot(x[0],x[1], marker=&#39;o&#39;, color=col, markersize=3) plt.figure() pentagon([0,0], depth=6, col) plt.show() The result of executing the above instructions 2.4.3 Heighway’s Dragon import math import numpy as np import matplotlib.pyplot as plt import numpy as np import matplotlib.pyplot as plt # Move point x by vector delta. def shift(x, delta): return np.add(x, delta) # Scale coordinates of point x by ratio. def scale(x, ratio): return np.multiply(x, ratio) # Rotate by angle of alpha (in degrees). def rotate(x, alpha): adeg = math.pi * alpha / 180 rotation_matrix = [ [np.cos(adeg), -np.sin(adeg)], [np.sin(adeg), np.cos(adeg)]] return np.matmul(x, rotation_matrix) def heighway(x, depth, col=&quot;black&quot;): if depth &gt; 1: x1 = rotate(x, -45) x1 = scale(x1, [np.sqrt(0.5), np.sqrt(0.5)]) heighway(x1, depth-1, col=&quot;blue&quot;) x2 = rotate(x, -45) x2 = scale(x2, [np.sqrt(0.5), np.sqrt(0.5)]) x2 = shift(x2, [0.75, 0.25]) heighway(x2, depth-1, col=&quot;red&quot;) else: plt.plot(x[0], x[1], marker=&#39;o&#39;, color=col, markersize=3) plt.figure() heighway([0,0], depth=14) plt.show() The result of executing the above instructions 2.4.4 Symmetric binary tree / Pythagoras’ tree import numpy as np import matplotlib.pyplot as plt # Move point x by vector delta. def shift(x, delta): return np.add(x, delta) # Scale coordinates of point x by ratio. def scale(x, ratio): return np.multiply(x, ratio) # Rotate by angle of alpha (in degrees). def rotate(x, alpha): adeg = math.pi * alpha / 180 rotation_matrix = [ [np.cos(adeg), -np.sin(adeg)], [np.sin(adeg), np.cos(adeg)]] return np.matmul(x, rotation_matrix) def sbt(x, depth, col=&quot;black&quot;): if depth &gt; 1: x1 = rotate(x, -45) x1 = shift(scale(x1, [0.7, 0.7]), [0, 1]) sbt(x1, depth-1, col=&quot;blue&quot;) x2 = rotate(x, 45) x2 = shift(scale(x2, [0.7, 0.7]), [0, 1]) sbt(x2, depth-1, col=&quot;red&quot;) else: plt.plot(x[0], x[1], marker=&#39;o&#39;, color=col, markersize=3) plt.figure() sbt([0,0], depth = 14) plt.show() The result of executing the above instructions "],["examples-in-r-1.html", "2.5 Examples in R", " 2.5 Examples in R The examples presented in this chapter repeat the composition of three atomic transformations – shift, rescale and rotate. Below are the definitions of these three transformations. In these examples, x is a two-element vector. # Move point x by delta. shift = function(x, delta) x + delta # Scale point x times ratio. scale = function(x, ratio) x * ratio # Rotate by alpha angle (in degrees). rotate = function(x, alpha) { sa = sin(pi * alpha / 180) ca = cos(pi * alpha / 180) x %*% matrix(c(ca, -sa, sa, ca), 2, 2, byrow = TRUE) } 2.5.1 Sierpiński triangle As we wrote at the beginning of this chapter, fractals can be built from ordinary dots, we do not need more sophisticated polygons. Let’s introduce it based on the Sierpiński triangle. \\[ y_1 = x * \\left[\\begin{smallmatrix} 0.5 &amp; 0\\\\ 0 &amp; 0.5 \\end{smallmatrix}\\right] \\] \\[ y_2 = x * \\left[\\begin{smallmatrix} 0.5 &amp; 0\\\\ 0 &amp; 0.5 \\end{smallmatrix}\\right] + \\left[\\begin{smallmatrix} 0.5 \\\\ 0 \\end{smallmatrix}\\right] \\] \\[ y_3 = x * \\left[\\begin{smallmatrix} 0.5 &amp; 0\\\\ 0 &amp; 0.5 \\end{smallmatrix}\\right] + \\left[\\begin{smallmatrix} 0.25 \\\\ \\sqrt3/4 \\end{smallmatrix}\\right] \\] # The notation x |&gt; scale(0.5) |&gt; shift(0.2) in R denotes the # tail composite of these functions and is equivalent to the notation # shift(scale(x, 0.5), 0.2). However, it is more readable. sierpinski &lt;- function(x, depth, col = &quot;black&quot;) { if (depth &gt; 1) { x1 = x |&gt; scale(0.5) sierpinski(x1, depth - 1, col = &quot;blue&quot;) x2 = x |&gt; scale(0.5) |&gt; shift(c(0.5, 0)) sierpinski(x2, depth - 1, col = &quot;red&quot;) x3 = x |&gt; scale(0.5) |&gt; shift(c(0.25, 0.5)) sierpinski(x3, depth - 1, col = &quot;orange&quot;) } else { points(x[1], x[2], pch = 19, col = col, cex=0.3) } } plot.new() plot.window(xlim=c(0, 1), ylim=c(0,1), asp=1) sierpinski(c(0,0), depth = 8) The result of executing the above instructions 2.5.2 Sierpiński pentagon pentagon &lt;- function(x, depth, color=&quot;black&quot;) { if (depth &gt; 1) { x1 = x |&gt; scale(0.382) pentagon(x1, depth - 1, color = &quot;blue&quot;) x2 = x |&gt; scale(0.382) |&gt; shift(c(0.618, 0)) pentagon(x2, depth - 1, color = &quot;red&quot;) x3 = x |&gt; scale(0.382) |&gt; shift(c(0.809, 0.588)) pentagon(x3, depth - 1, color = &quot;green&quot;) x4 = x |&gt; scale(0.382) |&gt; shift(c(0.309, 0.951)) pentagon(x4, depth - 1, color = &quot;orange&quot;) x5 = x |&gt; scale(0.382) |&gt; shift(c(-0.191, 0.588)) pentagon(x5, depth - 1, color = &quot;pink&quot;) } else points(x[1], x[2], pch = 19, col = color, cex=0.5) } plot.new() plot.window(xlim=c(-0.5,1.5), ylim=c(-0.1,1.7), asp=1) pentagon(c(0,0), depth = 6) The result of executing the above instructions 2.5.3 Heighway’s Dragon heighway &lt;- function(x, depth, color=&quot;black&quot;) { if (depth &gt; 1) { x1 = x|&gt; rotate(45)|&gt; scale(sqrt(0.5))|&gt; shift(c(1,0)) heighway(x1, depth-1, color=&quot;blue&quot;) x2 = x|&gt; rotate(45)|&gt; scale(sqrt(0.5)) heighway(x2, depth-1, color=&quot;red&quot;) } else points(x[1], x[2], pch=19, col=color, cex=0.5) } plot.new() plot.window(xlim=c(-1,2), ylim=c(-1.5,0.5), asp=1) heighway(c(1,1), depth = 15) The result of executing the above instructions 2.5.4 Symmetric binary tree / Pythagoras’ tree pitagoras = function(x, depth, color=&quot;black&quot;) { if (depth &gt; 1) { x1 = x|&gt; rotate(-45) |&gt; scale(sqrt(0.5)) |&gt; shift(c(0,1)) pitagoras(x1, depth-1, color=&quot;blue&quot;) x2 = x|&gt; rotate(45) |&gt; scale(sqrt(0.5)) |&gt; shift(c(0,1)) pitagoras(x2, depth-1, color=&quot;red&quot;) } else points(x[1], x[2], pch=19, col=color, cex=0.5) } plot.new() plot.window(xlim = c(-3,3), ylim = c(0,3), asp=1) pitagoras(c(1,1), depth = 15) The result of executing the above instructions "],["examples-in-julia-1.html", "2.6 Examples in Julia", " 2.6 Examples in Julia 2.6.1 Sierpiński triangle We can build fractals from ordinary dots, we do not need more sophisticated figures. The following example builds a Sierpiński triangle from dots. The following program repeats the sierpinski depth function composition a number of times. In theory, we would do this indefinitely, but it only takes a few steps to get a clear picture. The number of points grows exponentially, so after \\(k\\) steps it’s equal to \\(3^k\\) using Plots function sierpinski(x, y, depth) if depth &gt; 1 sierpinski(x/2, y/2, depth-1) sierpinski(x/2 + 0.5, y/2, depth-1) sierpinski(x/2 + 0.25, y/2 + 0.5, depth-1) else scatter!([x], [y], color=:black, legend=:false, markersize=2) end end # Initialize an empty graph and draw Sierpiński triangle. plot(0, xlim=(-0.1,1.1), ylim=(-0.1,1.1), axis=nothing) sierpinski(0, 0, 9) The result of executing the above instructions 2.6.2 Sierpiński pentagon # Recursively draw each arm of the pentagon. function pentagon(x, depth, col) if depth &gt; 1 x1 = 0.382x x2 = 0.382x + [0.618 0] x3 = 0.382x + [0.809 0.588] x4 = 0.382x + [0.309 0.951] x5 = 0.382x + [-0.191 0.588] pentagon(x1, depth-1, &quot;red&quot;) pentagon(x2, depth-1, &quot;blue&quot;) pentagon(x3, depth-1, &quot;green&quot;) pentagon(x4, depth-1, &quot;orange&quot;) pentagon(x5, depth-1, &quot;brown&quot;) else # We draw one point at a time, making the whole fractal creation time-consuming. # We will do it better in the next chapter. scatter!([x[1]], [x[2]], color=col, legend=:false, markersize=2) end end plot(0, xlim=(-0.35,1.35), ylim=(-0.1,1.6), axis=nothing) pentagon([0 0], 6, &quot;black&quot;) The result of executing the above instructions 2.6.3 Heighway’s Dragon In the Julia language, matrix addition and scaling are performed using standard operators. We need to define a function for rotating a vector by an angle \\(\\alpha\\). # Rotate by alpha angle (in degrees). function rotatex(x, alpha) sa = sin(pi * alpha / 180) ca = cos(pi * alpha / 180) [ca -sa; sa ca] * x end # Symbol &#39; stands for matrix transposition. # We need it to turn a row vector into a column vector. function heighway(x, depth, col) if depth &gt; 1 x1 = rotatex(x, -45) * sqrt(0.5) x2 = rotatex(x, -45) * sqrt(0.5) + [0.75 0.25]&#39; heighway(x1, depth-1, &quot;blue&quot;) heighway(x2, depth-1, &quot;red&quot;) else scatter!([x[1]], [x[2]], color=col, legend=:false, markersize=2) end end plot(0, xlim=(-0.5,1.5), ylim=(-1,0.5), axis=nothing) heighway([0 0]&#39;, 14, &quot;black&quot;) The result of executing the above instructions 2.6.4 Symmetric binary tree / Pythagoras’ tree The Pythagoras tree construction is very similar to the Heighway dragon. In the last chapter, we will show how to smoothly transition from one to the other. function sbt(x, depth, col) if depth &gt; 1 x1 = rotatex(x, -45) * 0.7 + [0 1]&#39; x2 = rotatex(x, 45) * 0.7 + [0 1]&#39; sbt(x1, depth-1, &quot;blue&quot;) sbt(x2, depth-1, &quot;red&quot;) else scatter!([x[1]], [x[2]], color =col, legend=:false, markersize = 2) end end plot(0, xlim=(-2,2), ylim=(0.5,3), axis=nothing) sbt([0 0]&#39;, 14, &quot;black&quot;) The result of executing the above instructions "],["gra-w-chaos.html", "Chapter 3 Gra w chaos", " Chapter 3 Gra w chaos Rozdział, w którym odkrywamy, że czasem losowe działania prowadzą do przewidywalnych i niezmiennych wyników, a twierdzenia matematyczne potrafią mieć zaskakujące zastosowania. Beta i Bit trafiają do Krakowa na Planty Rozmowa o całkach przyciąga zainteresowanych słuchaczy Stefana Banacha i Ottona Nikodyma a ich rozmowa przyciąga Hugona Steinhausa "],["hugo-steinhaus.html", "3.1 Hugo Steinhaus", " 3.1 Hugo Steinhaus Między duchem a materią pośredniczy matematyka. H. Steinhaus Hugo Steinhaus urodził się w 1887 roku w Jaśle. Od dziecka był błyskotliwy, przejawiał olbrzymi talent do języków i nauk ścisłych. Rodzina chciała zrobić z niego inżyniera, ale jego bardziej pociągała matematyka. I dobrze, ponieważ to jeden z najpłodniejszych polskich matematyków XX wieku. Dlaczego ludzie uczą się matematyki? Aby nauczać matematyki innych. H. Steinhaus Po ukończeniu gimnazjum rozpoczął studia na Uniwersytecie Lwowskim. Po roku przniósł się na Uniwersytet w Getyndze, będącej wtedy najważniejszym ośrodkiem matematycznym w Europie. W Getyndze uczył się pod kierunkiem wybitnych matematyków, w tym Davida Hilberta, u którego obronił pracę doktorską, i Felixa Kleina. Ścieżki wielkich umysłów często się przecinają, Steinhaus w Getyndze poznał np. Wacława Sierpińskiego. Po powrocie do Polski kontynuował badania naukowe to w Jaśle, to w Krakowie z przerwą na służbę w wojsku podczas I wojny światowej. W roku 1916 dokonał swojego największego odkrycia naukowego (jego własne słowa), mianowicie odkrył Stefana Banacha. Tak się złożyło, że Banach razem z Ottonem Nikodymem, czekając na swojego przyjaciela Witolda Wilkosza, rozmawiali o całkach Lebesgue’a. Zainteresowało to Steinhausa, przechodzącego nieopodal. Zaskoczyło go to, że w tak nietypowym miejscu usłyszał zaangażowane rozmowy o bardzo zaawansowanej matematyce. Podczas spotkania Steinhaus podzielił się z młodzieńcami problemem matematycznym, nad którym akurat pracował. Ku jego zaskoczeniu po kilku dniach Stefan Banach zgłosił się do niego z rozwiązaniem, które ostatecznie wspólnie opublikowali. Był to pierwszy artykuł Banacha i początek bardzo interesującej przyjaźni. Przyjaźni bardzo różnych osobowości. Banach lubił zabawę, nie dbał o konwenanse, Steinhaus był abstynentem, purystą językowym, zawsze pod krawatem. Jednak łączyła ich wspólna pasja i miłość do matematyki. Razem ze Banachem stworzyli lwowską szkołę matematyczną, która w szczytowym momencie zrzeszała ponad 20 wybitnych matematyków. Jeszcze we Lwowie Steinhaus zachęcał studentów matematyki do zajmowania się zastosowaniami matematyki. Często powtarzając, że ,,Matematyk zrobi to lepiej’’, zachęcał studentów, by mierzyli się z problemami z innych dziedzin, ponieważ często ścisły sposób myślenia pomaga w rozwiązywaniu najróżniejszych problemów. Sam dawał też świadectwo temu twierdzeniu. Chętnie współpracował z biologami, lekarzami, ekonomami i badaczami innych specjalizacji. Przykładowo, już po przeprowadzce do Wrocławia, współpraca z Ludwikiem Hirszfeldem doprowadziła do opracowania matematycznej teorii dochodzenia ojcostwa. We współpracy z dr. Rozenzweigiem badał optymalną taryfę za energię elektryczną z perspektywy producenta energii. Wynalazł i opatentował introwizor -– przyrząd do lokalizacji przedmiotów z użyciem promieniowania rentgenowskiego. Wynalazł longimetr – proste urządzenie do oszacowania długości nieregularnych krzywych, które znalazło wiele zastosowań w geografii. Przyrząd służący do szacowania długości krzywych. Przezroczystą folię kładzie się na krzywej i zlicza się liczbę przecięć krzywej z liniami siatek, tak otrzymuje się oszacowanie długości w określonej jednostce. We Wrocławiu pełnił funkcję kierownika działu zastosowań przyrodniczych i gospodarczych Instytutu Matematycznego PAN. Swoją pracownię nazwał ,,przychodnią matematyczną’‘, do której każdy może się zgłosić ze swoimi ,,chorobami matematycznymi’’ po poradę. Szacuje się, że ponad połowa z jego ponad 200 artykułów dotyczy zastosowań matematyki. Steinhaus był też znanym aforystą. Wiele z jego aforyzmów, które nazywano hugonotkami, przeszło do historii. Można je było znaleźć między innymi w czasopiśmie ,,Problemy’‘, w rubryce Cicer cum caule (łac. groch z kapustą), prowadzonej przez Juliana Tuwima. Legenda głosi, że gdy Tuwim pierwszy raz usłyszał aforyzm ,,Kula u nogi – Ziemia’’ z podziwu uklęknął przed Steinhausem. Geniusz – gen i już. H. Steinhaus Interesowała go też popularyzacja matematyki. Jeszcze w okresie międzywojennym napisał Kalejdoskop matematyczny, popularnonaukową książkę mającą pokazać różne oblicza matematyki. Książka ta doczekała się wielu wydań i tłumaczeń. Hugo Steinhaus inspirował matematyków nawet po śmierci. Przykładowo w roku 1990 na Politechnice Wrocławskiej powstało Centrum im. Hugona Steinhausa, promujące i rozwijające zastosowania matematyki w innych dziedzinach nauki. Steinhaus był też promotorem bardzo wielu aktywnych naukowców, którzy z kolei byli promotorami wielu kolejnych naukowców. Dziś w jego ,,matematycznym drzewie genealogicznym’’ znajduje się ponad 2940 matematyków, co jest niebywale wysoką liczbą jak na tak krótki czas. Jednym z ,,matematycznych potomków’’ Steinhausa jest też autor tej książki. "],["gra-w-chaos-1.html", "3.2 Gra w Chaos", " 3.2 Gra w Chaos Sposób generowania fraktali przedstawiony w poprzednim rozdziale opiera się na rekurencji. Składanie transformacji powoduje, że liczba obiektów, które musimy narysować, rośnie wykładniczo. W przypadku paproci, która składa się z czterech transformacji, wygenerowanie paproci na głębokości 10 wymaga narysowania \\(4^{10}\\) punktów (ponad milion). A 10 poziomów to bardzo mało, jeżeli chcemy uzyskać atrakcyjną grafikę w wysokiej rozdzielczości. Gdybyśmy chcieli wykonać 56 iteracji dla dywanu Sierpińskiego, to musielibyśmy narysować \\(8^{56} &gt; 10^{50}\\) punktów, czyli więcej niż jest atomów na całej Ziemi! Okazuje się, że fraktale oparte na składaniu kontrakcji można wygenerować w bardziej kontrolowany sposób. Co więcej, okaże się, że będzie on bazował na generowaniu losowych ruchów. Czytelniku, to będzie niesamowite! Powtarzanie wielokrotnie losowych ruchów będzie nas prowadziło nieustannie do niezmiennie stałych figur geometrycznych. Okazuje się, że nawet długie losowe trajektorie prowadzić mogą do przewidywalnych wzorców, i to właśnie będzie gra w chaos. 3.2.1 Gra w chaos i trójkąty Zacznijmy od prostego przykładu, który będzie uogólnioną metodą konstrukcji trójkąta Sierpińskiego. Prześledźmy następujący algorytm. Wybierz trzy dowolne niewspółliniowe punkty na płaszczyźnie. To będą wierzchołki A, B i C trójkąta Sierpińskiego. Wybierz dowolny punkt na płaszczyźnie. To będzie pozycja naszego pióra rysującego fraktal. Wybierz losowo wierzchołek A, B lub C i przesuń pióro o połowę w kierunku wybranego wierzchołka. Powtarzaj to losowanie i przesuwanie w nieskończoność (lub wystarczająco długo). Trojkąt złożony ze 100 000 punktów w grze w chaos Okazuje się, że gdy będziemy śledzić pozycję pióra, naszym oczom ukaże się trójkąt Sierpińskiego! 3.2.2 Co tu się dzieje? Zauważ, Drogi Czytelniku, że przesuwanie pióra o połowę odległości w kierunku wybranego wierzchołka jest równoznaczne z wykonaniem transformacji -&gt; pomniejsz obraz o 1/2 i przesuń w kierunku wybranego wierzchołka. Tak więc w rzeczywistości w losowy sposób wykonujemy jedną z transformacji: (1) pomniejsz 2-krotnie i przesuń w kierunku wierzchołka A, (2) pomniejsz 2-krotnie i przesuń w kierunku wierzchołka B lub (3) pomniejsz 2-krotnie i przesuń w kierunku wierzchołka C. W poprzednim rozdziale takie transformacje już wykorzystywaliśmy do budowy trójkąta Sierpińskiego. Ale stosowaliśmy jednocześnie wszystkie trzy, składając taką sumę transformacji wielokrotnie. Okazuje się, że nie musimy wykonywać tych transformacji jednocześnie, wystarczy wylosować jedną i powtarzać to losowanie w nieskończoność. 3.2.3 Gra w Chaos i fraktale Algorytm generowania z fraktali z użyciem gry w chaos polega na przekształcaniu jednego punktu (pióra) iteracyjnie przez losową wybraną transformację z pewnego zbioru transformacji. Każda transformacja musi być kontrakcją (w przykładach ograniczymy się do przekształceń afinicznych). Algorytm konstrukcji fraktali oparty na grze w chaos. Wybierz punkt początkowy dla pióra. Ze zbioru transformacji zwężających wylosuj jedną transformację i przekształć współrzędne pióra zgodnie z tą transformacją. Narysuj współrzędną pióra na ekranie. Wróć do kroku 2. Pokażemy, jak ten algorytm działa na przykładzie konstrukcji paproci Barnsleya, ale dla wygody najpierw przedstawimy alternatywny sposób zapisu transformacji afinicznych. 3.2.4 Przekształcenia afiniczne W poprzednim rozdziale przekształcenia afiniczne definiowaliśmy przez dowolne złożenie trzech rodzajów transformacji – przesunięcia, obrotu oraz skalowania (w tym odbicia pionowego lub poziomego), przy czym skalowanie musiało mieć skalę mniejszą niż 1 co do wartości bezwzględnej, aby było zwężające. Taka reprezentacja jest wygodna dla ludzi, ponieważ łatwo na jej podstawie wyobrazić sobie, co się dzieje z wyjściowymi figurami. Okazuje się jednak, że dla komputera znacznie wygodniejszą reprezentacją przekształcenia afinicznego jest postać macierzowa transformacji. W zapisie macierzowym każdą transformację afiniczną \\((x&#39;, y&#39;) = f(x, y)\\) w przestrzeni dwuwymiarowej można przedstawić za pomocą sześciu liczb \\((a, b, c, d, e, f)\\). \\[ \\begin{bmatrix} x&#39; \\\\ y&#39; \\end{bmatrix} = \\begin{bmatrix} a &amp; b \\\\ d &amp; e \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} c \\\\ f \\end{bmatrix} = \\begin{bmatrix} a x + b y + c \\\\ d x + e y + f \\end{bmatrix}. \\] Jeżeli znamy podstawy algebry macierzowej, to z reprezentacji opartej na obrotach, przesunięciach i skalowaniu możemy łatwo wyliczyć współczynniki \\(a\\)–\\(f\\). Kilka przykładów odpowiadających sobie reprezentacji przekształceń afinicznych znajduje się w kolejnym rozdziale. Teraz jednak zobaczmy, jak przy użyciu gry w chaos skonstruować paproć. 3.2.5 Paprocie i chaos Tabela 1 przedstawia cztery transformacje afiniczne zapisane za pomocą notacji macierzowej. a b c d e f \\(T_1\\): łodyżka 0,00 0,00 0 0,00 0,16 0,00 \\(T_2\\): góra 0,85 0,04 0 $-$0,04 0,85 1,60 \\(T_3\\): lewy liść 0,20 $-$0,26 0 0,23 0,22 0,80 \\(T_4\\): prawy liść $-$0,15 0,28 0 0,26 0,24 0,44 [Współczynniki transformacji składających się na paproć Barnsleya] Aby narysować paproć z poniższego rysunku, wystarczy wziąć losowy punkt, a następnie 100 000 razy powtórzyć trzy kroki: wylosować jedną z transformacji z tej tabeli, stosując prawdopodobieństwa losowania 1%, 79%, 10%, 10% dla kolejnych transformacji, przekształcić współrzędne punktu wylosowaną transformacją, narysować punkt na wykresie. Ilustracja czterech transformacji (obrysowanych czerwonymi prostokątami) na bazie paproci Barnsleya Przy okazji widać, że mamy olbrzymią redukcję informacji – taką piękną paproć opisaliśmy wyłącznie z użyciem 24 liczb. Ta obserwacja stała się fundamentem kompresji fraktalnej, dziedziny, która zamierzała zmniejszyć istotnie opis graficznych figur, stosując ich reprezentację fraktalną. Częściej losujemy lewy i prawy liść, rzadziej górę Częściej losujemy łodyżkę, znacznie rzadziej liście Nie losujemy łodyżki Wybór punktu \\(x_0\\) nie ma znaczenia, ale jeżeli bardzo odstaje od fraktala, to z przyczyn wizualnych warto pominąć kilka pierwszych kroków gry w chaos, tak by żadne punkty za bardzo nie odstawały od głównego obrazu. Jaką rolę odgrywają prawdopodobieństwa w tworzeniu fraktala? Zauważmy, że prawdopodobieństwo wylosowania łodyżki jest mniejsze niż głównej części paproci, również dlatego, że łodyżka zajmuje mało miejsca i nie ma co marnować czasu, losując punkty z łodyżki. Na marginesie możemy przyjrzeć się trzem różnym paprociom Barnsleya, które składają się z tych samych transformacji, przedstawionych w tabeli 1, ale w których zastosowano różne prawdopodobieństwa. Ogólny zarys każdej z tych paproci jest podobny, ale widzimy, że sterując prawdopodobieństwami, możemy otrzymać mniej lub bardziej ażurowe konstrukcje. 3.2.6 Bardziej formalnie Jeżeli już mamy zbudowaną intuicję, jak działa gra w chaos, to warto zapisać to, co się wydarzyło, bardziej formalnie. Mamy zbiór \\(K\\) przekształceń \\(f_i:R^2 \\rightarrow R^2\\), które są przekształceniami zwężającymi, czyli spełniającymi warunek: \\[ \\exists_{\\lambda &lt; 1}\\forall_{x, y} \\lambda d(x,y) \\geq d(f(x), f(y)). \\] Mamy wektor \\(K\\) prawdopodobieństw wylosowania kolejnych przekształceń \\(\\pi_i \\geq 0\\). Prawdopodobieństwa sumują się do 1, czyli \\(\\sum_{i=1}^K \\pi_i = 1\\). Ciąg punktów \\(x_0\\), \\(f_{a_1}(x_0)\\), \\(f^2(x_0) = f_{a_2}(f_{a_1}(x_0))\\), \\(f^3(x_0) = f_{a_3}(f_{a_2}(f_{a_1}(x_0)))\\), … tworzy obraz fraktala. Symbol \\(a_i\\) oznacza i-tą wylosowaną wartość ze zbioru \\(1...K\\) przy losowaniu z prawdopodobieństwem \\(\\pi_1, ..., \\pi_K\\). Wybór punktu \\(x_0\\) nie ma znaczenia. "],["zastosowania.html", "3.3 Zastosowania", " 3.3 Zastosowania 3.3.1 Gra w chaos i genetyka Czytelniku, poświęć chwilę, by zastanowić się nad konsekwencjami ostatniego przykładu. Dobierając różne prawdopodobieństwa, otrzymujemy wizualnie inne figury. W nieskończoności cały fraktal by się wysycił, ale przy skończonej liczbie kroków gęstość punktów koduje informacje o rozkładzie losowanych transformacji. Ta obserwacja przyczyniła się do szeregu ciekawych zastosowań gry w chaos do kodowania informacji w sekwencjach o różnej długości. Okazuje się, że na fraktale możemy ,,nawijać’’ ciągi pozornie losowych symboli tak by wizualnie badać częstości względnego występowania tych symboli. Przyjrzyjmy się zastosowaniu tego pomysłu do kodowania sekwencji genetycznych. Sekwencje składają się z ciągów liter A, C, T i G. Rozważmy cztery transformacje polegające na dwukrotnym zmniejszeniu i przesunięciu w stronę jednego z rogów kwadratu. Gra w chaos na sekwencjach biologicznych. Lewy panel ilustruje metodę działania kodowania. Prawy panel koduje sekwencję genetyczną wirusa SARS-CoV-2 Teraz zamiast losować transformację, możemy czytać jakąś sekwencję genetyczną i wybierać transformację w zależności od napotkanej litery lub ciągu liter. Dzięki temu często występujące wzorce w sekwencji będą wizualnie zakodowane we fraktalu. Powyższy przykład koduje sekwencję wirusa SARS-CoV-2 za pomocą czterech transformacji. Inne pomysły na kodowanie sekwencji biologicznych z użyciem gry w chaos można znaleźć w artykule Chaos game representation and its applications in bioinformatics [LöHe21]. 3.3.2 Gra w chaos i muzyka Zastosowań dla matematyki fraktalnej szukano również w muzyce. W literaturze, zarówno naukowej, jak i popularnonaukowej, można znaleźć liczne przykłady różnorodnych prób połączenia muzyki z fraktalami. Począwszy od wykorzystywania fraktali do generowania muzyki, która nie jest ani zbyt monotonna, ani zbyt chaotyczna, po zastosowanie fraktali do badania przewidywalności różnych gatunków muzycznych [K.Hs91]. Przykładowo, w roku 2012 w popularnym magazynie ,,Wired’’ zaprezentowano analizę fraktalną różnych utworów muzycznych. Utwory zostały najpierw opisane w języku składowych harmonicznych, a następnie przeprowadzono na nich analizę wymiaru fraktalnego, stwierdzając, że najbardziej przewidywalne są symfonie, a najmniej przewidywalne są utwory ragtime. 3.3.3 Wymiar fraktalny mózgu W poprzednim rozdziale przedstawiliśmy definicję wymiaru pudełkowego. Myliłby się ten, kto założy, że będzie ona wykorzystywana jedynie do fraktali. Praktycy znaleźli dla niej wiele ciekawych zastosowań, jak np. mierzenie stopnia poszarpania linii brzegowej różnych państw. Przykładowo wymiar pudełkowy wybrzeża Australii wynosi 1,143 (według Fractal dimension of coastline of Australia. [HRBS21]), co świadczy o dużej nieregularności. To jednak znacznie mniej niż wymiar bardzo poszarpanego wybrzeża Norwegii, który wynosi 1,3727. Udało się również zmierzyć wymiary fraktalne obiektów anatomicznych, takich jak mózg czy płuca. Okazuje się, że powierzchnia mózgu ma wymiar 2,79, będący dowodem dużego pofałdowania tego organu. Powierzchnia płuc ma jeszcze wyższy wymiar, dochodzący do wartości 2,97 (według List of fractals by Hausdorff dimension [Wiki22]). W literaturze medycznej znaleźć można przykłady analiz wykorzystujących wymiar fraktalny określonych struktur anatomicznych w detekcji chorób. Poniżej przedstawiamy rysunek z artykułu Fractal Analysis of Lung Structure in Chronic Obstructive Pulmonary Disease [TSSH20] poświęconego użyciu wymiaru fraktalnego w analizie przewlekłej choroby płuc. Przewlekłe choroby mogą prowadzić do zmian struktur anatomicznych, które można ilościowo opisać wymiarem fraktalnym. Pomaga to zarówno zrozumieć zmiany wywołane chorobą, jak i budować modele predykcyjne wspierające diagnostykę. Wykres z pracy Fractal analysis of lung structure in chronic obstructive pulmonary disease, badającej możliwość użycia wymiaru fraktalnego naczyń krwionośnych płuc w analizie chorób przewlekłych płuc. Panel A pokazuje schematyczne struktury głównych naczyń krwionośnych, panel B przedstawia, jak liczba pudełek rośnie z malejącą wielkością boku pudełka Gdzie jeszcze można zastosować geometrię fraktalną? Z pewnością jeszcze wiele ciekawych odkryć przed nami. Bibliografia "],["przykłady-w-języku-python.html", "3.4 Przykłady w języku Python", " 3.4 Przykłady w języku Python 3.4.1 Trójkąt Sierpińskiego raz jeszcze Poniższy kod odtwarza konstrukcję trójkąta Sierpińskiego przedstawioną w tym rozdziale. W wektorze triangle definiujemy trzy wierzchołki trójkąta, a w obiekcie point umieszczamy współrzędne punktu startowego dla konstrukcji fraktala. Następnie w pętli przesuwamy punkt w kierunku losowego wierzchołka. \\(x&#39; = x/2\\), \\(y&#39; = y/2\\) (lewy róg) \\(x&#39; = x/2 + \\frac 12\\), \\(y&#39; = y/2\\) (prawy róg) \\(x&#39; = x/2 + \\frac 14\\), \\(y&#39; = y/2 + \\frac{\\sqrt{3}}2\\) (górny róg) import numpy as np import matplotlib.pyplot as plt # Liczba kroków gry w chaos. N = 200000 x_vec, y_vec, col_vec = [], [], [] # Współrzędne wierzchołków trójkąta. triangle = [[0,0], [0.5, 2], [1.5,0.5]] point = [0.1, 0] # Losujemy numer wierzchołka, w kierunku którego przesuniemy punkt. for i in range(N): ind = np.random.choice(range(3)) point = np.multiply(np.add(point, triangle[ind]), 0.5) x_vec.append(point[0]) y_vec.append(point[1]) col_vec.append(ind) # Rysujemy wykres kropkowy z odwiedzonych punktów. # Kolory odpowiadają wylosowanej transformacji. plt.scatter(x_vec, y_vec, s=0.2, c = col_vec) plt.axis(&#39;off&#39;) plt.show() 3.4.2 Paproć Barnsleya import numpy as np import matplotlib.pyplot as plt # Cztery transformacje składające się na paproć. def trans1(x,y): return (0., 0.16*y) def trans2(x,y): return (0.85*x + 0.04*y, -0.04*x + 0.85*y + 1.6) def trans3(x,y): return (0.2*x - 0.26*y, 0.23*x + 0.22*y + 0.8) def trans4(x,y): return (-0.15*x + 0.28*y, 0.26*x + 0.24*y + 0.44) # Lista transformacji i wektor z prawdopodobieństwami wylosowania # każdej z transformacji. N, x, y = 200000, 0, 0 x_vec, y_vec, col_vec = [], [], [] trans = [trans1, trans2, trans3, trans4] probs = [0.01, 0.79, 0.1, 0.1] for i in range(N): # Losujemy jedną z czterech transformacji. ind = np.random.choice(range(len(trans)), p=probs) selected = trans[ind] x, y = selected(x,y) x_vec.append(x) y_vec.append(y) col_vec.append(ind) plt.scatter(y_vec, x_vec, s=0.2, c=col_vec) plt.show() 3.4.3 Liść klonu import numpy as np import matplotlib.pyplot as plt def transform(x,y, affine): return(affine[0]*x + affine[1]*y + affine[2], affine[3]*x + affine[4]*y + affine[5]) N, x, y = 200000, 0, 0 x_vec, y_vec, col_vec = [], [], [] # Lista transformacji. affines = [[0.14, 0.01, -0.08, 0.0, 0.51, -1.31], [0.43, 0.52, 1.49, -0.45, 0.5, -0.75], [0.45, -0.49, -1.62, 0.47, 0.47, -0.74], [0.49, 0.0, 0.02, 0.0, 0.51, 1.62]] probs = [0.25, 0.25, 0.25, 0.25] for i in range(N): ind = np.random.choice(range(len(affines)), p=probs) x, y = transform(x,y, affines[ind]) x_vec.append(x) y_vec.append(y) col_vec.append(ind) plt.scatter(x_vec, y_vec, s=0.2, c=col_vec) plt.show() 3.4.4 Spirala Transformacje tworzące spiralę. affines = [[0.7878, -0.4242, 1.7586, 0.2424, 0.8598,1.408], [-0.1212, 0.2575, -6.7216, 0.1515, 0.05303, 1.3772], [0.1818, -0.1363, 6.0861, 0.0909, 0.1818, 1.5680]] probs = [0.9, 0.05, 0.05] "],["przykłady-w-języku-r.html", "3.5 Przykłady w języku R", " 3.5 Przykłady w języku R 3.5.1 Trójkąt Sierpińskiego raz jeszcze Poniższy kod odtwarza konstrukcję trójkąta Sierpińskiego przedstawioną w tym rozdziale. W wektorze triangle definiujemy trzy wierzchołki trójkąta, a w obiekcie point umieszczamy współrzędne punktu startowego dla konstrukcji fraktala. Następnie w pętli przesuwamy punkt w kierunku losowego wierzchołka. \\(x&#39; = x/2\\), \\(y&#39; = y/2\\) (lewy róg) \\(x&#39; = x/2 + \\frac 12\\), \\(y&#39; = y/2\\) (prawy róg) \\(x&#39; = x/2 + \\frac 14\\), \\(y&#39; = y/2 + \\frac{\\sqrt{3}}2\\) (górny róg) N = 200000 x = y = 0 plot(0, xlim = c(0,1), ylim = c(0,0.9), xlab = &quot;&quot;, ylab = &quot;&quot;, col=&quot;white&quot;, asp=1) for (i in 1:N) { # Trzy transformacje zapisujemy jako różne scenariusze w bloku instrukcji switch. ind = sample(1:3, 1) switch(ind, &#39;1&#39; = {x &lt;- x/2; y &lt;- y/2}, &#39;2&#39; = {x &lt;- x/2 + 1/2; y &lt;- y/2}, &#39;3&#39; = {x &lt;- x/2 + 1/4; y &lt;- y/2 + sqrt(3)/4}) points(x, y, pch = &quot;.&quot;, col=ind) } 3.5.2 Paproć Barnsleya trans1 = function(x,y) c(0., 0.16*y) trans2 = function(x,y) c(0.85*x + 0.04*y, -0.04*x + 0.85*y + 1.6) trans3 = function(x,y) c(0.2*x - 0.26*y, 0.23*x + 0.22*y + 0.8) trans4 = function(x,y) c(-0.15*x + 0.28*y, 0.26*x + 0.24*y + 0.44) # W tym przykładzie transformacje (które są funkcja) # złożyliśmy w listę, aby łatwiej było na nich pracować. trans = list(trans1, trans2, trans3, trans4) probs = c(0.01, 0.79, 0.1, 0.1) N = 200000 x = y = 0 plot(0, xlim = c(-2.5,2.5), ylim = c(0,10), xlab = &quot;&quot;, ylab = &quot;&quot;, col=&quot;white&quot;, asp=1) for (i in 1:N) { ind = sample(seq_along(trans), 1, prob = probs) res = trans[[ind]](x, y) x = res[1] y = res[2] points(x, y, pch = &quot;.&quot;, col=ind) } 3.5.3 Liść klonu transform = function(x,y, affine) c(affine[1]*x + affine[2]*y + affine[3], affine[4]*x + affine[5]*y + affine[6]) N = 400000 x = y = 0 # Lista transformacji, przechowujemy ją jako listę wektorów # o długości 6. affines = list(c(0.14, 0.01, -0.08, 0.0, 0.51, -1.31), c(0.43, 0.52, 1.49, -0.45, 0.5, -0.75), c(0.45, -0.49, -1.62, 0.47, 0.47, -0.74), c(0.49, 0.0, 0.02, 0.0, 0.51, 1.62)) probs = c(0.25, 0.25, 0.25, 0.25) plot(0, xlim = c(-3.5,3.5), ylim = c(-3.5,3.5), xlab = &quot;&quot;, ylab = &quot;&quot;, col=&quot;white&quot;, asp=1) for (i in 1:N) { # Losujemy transformacje uwzględniając prawdopodobieństwa # wskazane w wektorze probs ind = sample(seq_along(affines), 1, prob = probs) res = transform(x, y, affines[[ind]]) x = res[1] y = res[2] points(x, y, pch = &quot;.&quot;, col=ind) } 3.5.4 Spirala Transformacje tworzące spiralę. affines = list( c(0.7878, -0.4242, 1.7586, 0.2424, 0.8598, 1.4080), c(-0.1212, 0.2575, -6.7216, 0.1515, 0.05303, 1.3772), c(0.1818, -0.1363, 6.0861, 0.0909, 0.1818, 1.5680)) probs = c(0.9, 0.05, 0.05) "],["przykłady-w-języku-julia.html", "3.6 Przykłady w języku Julia", " 3.6 Przykłady w języku Julia 3.6.1 Trójkąt Sierpińskiego raz jeszcze Poniższy kod odtwarza konstrukcję trójkąta Sierpińskiego przedstawioną w tym rozdziale. W macierzy triangle definiujemy trzy wierzchołki trójkąta, a w obiekcie point umieszczamy współrzędne punktu startowego dla konstrukcji fraktala. Następnie w pętli przesuwamy punkt w kierunku losowego wierzchołka. \\(x&#39; = x/2\\), \\(y&#39; = y/2\\) (lewy róg) \\(x&#39; = x/2 + \\frac 12\\), \\(y&#39; = y/2\\) (prawy róg) \\(x&#39; = x/2 + \\frac 14\\), \\(y&#39; = y/2 + \\frac{\\sqrt{3}}2\\) (górny róg) using Plots # Liczba kroków, wierzchołki trójkąta i kolory dla transformacji. N = 100000 triangle = [0 0; 0.5 2; 1.5 0.5] col = [&quot;red&quot; &quot;green&quot; &quot;blue&quot;] point = [0.1 0] # Macierz na kolejne punkty trójkąta Sierpińskiego. points = zeros(N, 2) cols = String[] # Wektor cols zbiera kolory odpowiadające wylosowanym # transformacjom a macierz coords zbiera współrzędne # pióra po każdym skoku. for i in 1:N ind = rand(1:3,1) append!(cols, col[ind]) point = (point + triangle[ind, :])/2 coords[i,:] = point end scatter(coords[:,1], coords[:,2], color=cols, legend=:false, markersize=2, axis=nothing) 3.6.2 Paproć Barnsleya using StatsBase # Kolejne transformacje są zapisane jako osobne funkcje, # które później złożą się na wektor funkcji trans. trans1(x) = [ 0. 0.; 0. 0.16]*x trans2(x) = [0.85 0.04; -0.04 0.85]*x + [0; 1.6] trans3(x) = [0.2 -0.26; 0.23 0.22]*x + [0; 0.8] trans4(x) = [-0.15 0.28; 0.26 0.24]*x + [0; 0.44] trans = [trans1, trans2, trans3, trans4] point = [0 0]&#39; col = [&quot;red&quot; &quot;green&quot; &quot;blue&quot; &quot;orange&quot;] probs = [0.01, 0.79, 0.1, 0.1] N = 200000 coords = zeros(N, 2) cols = String[] for i in 1:N # Losujemy transformacje wykorzystując wektor *probs* z częstościami # występowania poszczególnych transformacji. Funkcja sample # jest dostępna w bibliotece StatsBase. ind = sample(1:length(probs), Weights(probs)) selected_trans = trans[ind[1]] point = selected_trans(point) coords[i,:] = point push!(cols, col[ind]) end scatter(coords[:,1], coords[:,2], color=cols, legend=:false, markersize=1, axis=nothing, markerstrokecolor=cols) 3.6.3 Liść klonu # Kolejne transformacje zapisujemy jako macierze 3x3 przekształceń # liniowych. Przez co zapis jest bardziej kompaktowy. affines = [[0.14 0.01 -0.08; 0.0 0.51 -1.31; 0 0 1], [0.43 0.52 1.49; -0.45 0.5 -0.75 ; 0 0 1], [0.45 -0.49 -1.62; 0.47 0.47 -0.74; 0 0 1], [0.49 0.0 0.02; 0.0 0.51 1.62 ; 0 0 1]] probs = [0.25, 0.25, 0.25, 0.25] col = [&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;orange&quot;] N = 200000 point = [0 0 1]&#39; coords = zeros(N, 2) cols = String[] for i in 1:N # W przeciwieństwie do poprzednich rozdziałów, tutaj nie # korzystamy z rekurencji. Iteracyjnie liczymy pozycje dla # N skoków a później wszystkie wyznaczone punkty rysujemy # jedną instrukcją scatter. ind = sample(1:length(probs), Weights(probs)) point = affines[ind[1]] * point coords[i,:] = point[1:2] push!(cols, col[ind]) end scatter(coords[:,1], coords[:,2], color=cols, legend=:false, markersize=1, axis=nothing, markerstrokecolor=cols) 3.6.4 Spirala Transformacje tworzące spiralę. affines = [ [0.7878 -0.4242 1.7586; 0.2424 0.8598 1.408; 0 0 1], [-0.1212 0.2575 -6.7216; 0.1515 0.0530 1.3772; 0 0 1], [0.1818 -0.1363 6.0861; 0.0909 0.1818 1.5680; 0 0 1]] probs = [0.9, 0.05, 0.05] "],["kieszonkowy-atlas-fraktali.html", "Chapter 4 Kieszonkowy atlas fraktali", " Chapter 4 Kieszonkowy atlas fraktali Omawiane w tej książce fraktale określane są też jako system iterowanych kontrakcji (ang. iterated function system, IFS). Nie każdy fraktal można w ten sposób wygenerować (patrz zbiory Julii lub żuka Mandelbrota), ale wiele można. W tym rozdziale przypomnimy kilka ciekawszych. Beta i Bit wracają do bazy "],["paproć-barnsleya-3.html", "4.1 Paproć Barnsleya", " 4.1 Paproć Barnsleya Ten bardzo popularny fraktal został po raz pierwszy opisany dopiero w 1993 roku przez Michaela Barnsleya. Autor badał możliwości opisu różnych obiektów, w znacznej części roślin, za pomocą fraktali, a w szczególności systemów iterowanych kontrakcji. Badania te doprowadziły do ciekawych rozszerzeń fraktali, np. superfraktali lub parametryzowanych V-fraktali, które umożliwiają mieszanie i mutowanie figur fraktalnych. Opis i przykłady dostępne są w pracy V-variable fractals and superfractals. Podstawowa wersja paproci jest oparta na czterech, pokazanych niżej, transformacjach. Składowe transformacje dla paproci Barnsleya. Kolorem oznaczono obrazy kolejnych transformacji. Wykres uzyskany algorytmem gry w chaos z prawdopodobieństwami \\(\\pi = [0,01; 0,79; 0,1; 0,1]\\). \\[ f_1(x, y) = \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0,16 &amp; 0 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} 0,85 &amp; 0,04 &amp; 0 \\\\ -0,04 &amp; 0,85 &amp; 1,6 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_3(x, y) = \\begin{bmatrix} 0,2 &amp; -0,26 &amp; 0 \\\\ 0,23 &amp; 0,22 &amp; 0,8 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_4(x, y) = \\begin{bmatrix} -0,15 &amp; 0,28 &amp; 0 \\\\ 0,26 &amp; 0,24 &amp; 0,44 \\end{bmatrix} [x \\ y \\ 1]^T \\] Eksperymenty z paprociami. Wariacje na temat paproci z nieznacznie zmodyfikowanymi transformacjami. "],["liść-klonu-3.html", "4.2 Liść klonu", " 4.2 Liść klonu Ciekawy fraktal zaproponowany przez Paula Bourke’a. W konstrukcji przypomina paproć, ale z innymi proporcjami poszczególnych składowych (mniejszy główny liść, większe poboczne i ogonek). Poniższy obrazek ilustruje liść klonu i wszystkie cztery transformacje. Składowe transformacje dla liścia klonu. Kolorem oznaczono obrazy kolejnych transformacji. Wykres uzyskany algorytmem gry w chaos z prawdopodobieństwami \\(\\pi = [0,25; 0,25; 0,25; 0,25]\\). \\[ f_1(x, y) = \\begin{bmatrix} 0,14 &amp; 0,01 &amp; -0,08 \\\\ 0 &amp; 0,51 &amp; -1,31 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} 0,43 &amp; 0,52 &amp; 1,49 \\\\ -0,45 &amp; 0,5 &amp; -0,75 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_3(x, y) = \\begin{bmatrix} 0,45 &amp; -0,49 &amp; -1,62 \\\\ 0,47 &amp; 0,47 &amp; -0,74 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_4(x, y) = \\begin{bmatrix} 0,49 &amp; 0 &amp; 0,02 \\\\ 0 &amp; 0,51 &amp; 1,62 \\end{bmatrix} [x \\ y \\ 1]^T \\] "],["pięciokrotka-mcwortera-ang.-mcworters-pentigree.html", "4.3 Pięciokrotka McWortera (ang. McWorter’s pentigree)", " 4.3 Pięciokrotka McWortera (ang. McWorter’s pentigree) William McWorter w 1990 roku zaproponował ciekawą rodzinę fraktali opartą na bardzo prostych geometrycznych transformacjach. Poniższy fraktal wykorzystuje sześć transformacji, z których każda skaluje wyjściową figurę o \\(\\frac{3 - \\sqrt 5}{2} \\approx 0,38196\\), a następnie obraca o \\(36^\\circ\\); \\(108^\\circ\\); \\(-36^\\circ\\); \\(-108^\\circ\\); \\(-36^\\circ\\) i \\(36^\\circ\\) stopni i odpowiednio ją przesuwa. Składowe transformacje dla pięciokrotki McWortera. Kolorem oznaczono obrazy kolejnych transformacji. Wykres uzyskany algorytmem gry w chaos z prawdopodobieństwami \\(1/6\\). \\[ f_1(x, y) = \\begin{bmatrix} 0,309 &amp; -0,255 &amp; 0 \\\\ 0,255 &amp; 0,309 &amp; 0 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} -0,118 &amp; -0,363 &amp; 0,309 \\\\ 0,363 &amp; -0,118 &amp; 0,225 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_3(x, y) = \\begin{bmatrix} 0,309 &amp; 0,225 &amp; 0,191 \\\\ -0,225 &amp; 0,309 &amp; 0,588 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_4(x, y) = \\begin{bmatrix} -0,118 &amp; 0,363 &amp; 0,500 \\\\ -0,363 &amp; -0,118 &amp; 0,363 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_5(x, y) = \\begin{bmatrix} 0,309 &amp; 0,225 &amp; 0,382 \\\\ -0,225 &amp; 0,309 &amp; 0 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_6(x, y) = \\begin{bmatrix} 0,309 &amp; -0,225 &amp; 0,691 \\\\ 0,225 &amp; 0,309 &amp; -0,225 \\end{bmatrix} [x \\ y \\ 1]^T \\] "],["drzewa.html", "4.4 Drzewa", " 4.4 Drzewa Składając kilka transformacji, możemy uzyskać bardziej złożone i bardziej kontrolowane fraktale. Poniżej zamieszczamy przykłady dwóch fraktali wyglądających jak drzewa. Pierwszy złożony jest z pięciu, a drugi z siedmiu transformacji. Gdy już dostrzeże się ideę stojącą za konstrukcją drzewa, łatwo zaproponować własne zmiany i rozszerzenia. Składowe transformacje dla liścia klonu. Kolorem oznaczono obrazy kolejnych transformacji. Każda transformacja losowana jest z równym prawdopodobieństwem \\(1/5\\). \\[ f_1(x, y) = \\begin{bmatrix} 0,195 &amp; -0,488 &amp; 0,4431 \\\\ 0,344 &amp; 0,443 &amp; 0,2452 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} 0,462 &amp; 0,414 &amp; 0,2511 \\\\ -0,252 &amp; 0,361 &amp; 0,5692 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_3(x, y) = \\begin{bmatrix} -0,637 &amp; 0 &amp; 0,8562 \\\\ 0 &amp; 0,501 &amp; 0,2512 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_4(x, y) = \\begin{bmatrix} -0,035 &amp; 0,07 &amp; 0,4884 \\\\ -0,469 &amp; 0,022 &amp; 0,507 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_5(x, y) = \\begin{bmatrix} -0,058 &amp; -0,07 &amp; 0,597 \\\\ 0,453 &amp; -0,111 &amp; 0,097 \\end{bmatrix} [x \\ y \\ 1]^T \\] Niektóre transformacje nakładają się na siebie, by uzyskać efekt grubszego pnia lub grubszej gałęzi. Fragmenty tego drzewa można dodatkowo rozjaśnić lub przyciemnić, zmieniając prawdopodobieństwo wylosowania transformacji. Składowe transformacje dla liścia klonu. Kolorem oznaczono obrazy kolejnych transformacji. Każda transformacja losowana jest z równym prawdopodobieństwem \\(1/7\\). \\[ f_1(x, y) = \\begin{bmatrix} 0,05 &amp; 0 &amp; -0,06\\\\ 0 &amp; 0,4 &amp; -0,47 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} -0,05 &amp; 0 &amp; -0,06 \\\\ 0 &amp; -0,4 &amp; -0,47 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_3(x, y) = \\begin{bmatrix} 0,03 &amp; -0,14 &amp; -0,16 \\\\ 0 &amp; 0,26 &amp; -0,01 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_4(x, y) = \\begin{bmatrix} -0,03 &amp; 0,14 &amp; -0,16 \\\\ 0 &amp; -0,26 &amp; -0,01 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_5(x, y) = \\begin{bmatrix} 0,56 &amp; 0,44 &amp; 0,3 \\\\ -0,37 &amp; 0,51 &amp; 0,15 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_6(x, y) = \\begin{bmatrix} 0,19 &amp; 0,07 &amp; -0,2 \\\\ -0,1 &amp; 0,15 &amp; 0,28 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_7(x, y) = \\begin{bmatrix} -0,33 &amp; -0,34 &amp; -0,54 \\\\ -0,33 &amp; 0,34 &amp; 0,39 \\end{bmatrix} [x \\ y \\ 1]^T \\] "],["spirala-3.html", "4.5 Spirala", " 4.5 Spirala Stosując obroty, można otrzymać bardzo ciekawe spiralne kształty. Interesujący efekt można uzyskać już przy dwóch transformacjach: Transformacja 1: przeskalowanie figury o 90% i obrót o 20 stopni. Transformacja 2: przeskalowanie figury o 10%, obrót o 20 stopni i przesunięcie o 1 w osi poziomej. Składowe transformacje dla spirali. Kolorem oznaczono obrazy kolejnych transformacji. Wykres uzyskany algorytmem gry w chaos z prawdopodobieństwami \\(\\pi = [0,9; 0,1]\\). \\[ f_1(x, y) = \\begin{bmatrix} 0,787 &amp; -0,424 &amp; 1,758647 \\\\ 0,242 &amp; 0,859 &amp; 1,408 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} 0,181 &amp; -0,136 &amp; 6,086 \\\\ 0,090 &amp; 0,181 &amp; 1,568 \\end{bmatrix} [x \\ y \\ 1]^T \\] Dodając dodatkowe transformacje, możemy wzbogacić tę spiralę o drugi warkocz. Czytelnik może swobodnie eksperymentować z dodatkowymi warkoczami, wystarczy dodać jeszcze jedną pomniejszającą transformację. Składowe transformacje dla podwójnej spirali. Kolorem oznaczono obrazy kolejnych transformacji. Wykres uzyskany algorytmem gry w chaos z prawdopodobieństwami \\(\\pi = [0,7; 0,15; 0,15]\\). \\[ f_1(x, y) = \\begin{bmatrix} 0,787 &amp; -0,424 &amp; 1,758647 \\\\ 0,242 &amp; 0,859 &amp; 1,408 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} -0,121 &amp; 0,257 &amp; -6,721 \\\\ 0,151 &amp; 0,053 &amp; 1,377 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_3(x, y) = \\begin{bmatrix} 0,181 &amp; -0,136 &amp; 6,086 \\\\ 0,090 &amp; 0,181 &amp; 1,568 \\end{bmatrix} [x \\ y \\ 1]^T \\] "],["wielokąty-sierpińskiego.html", "4.6 Wielokąty Sierpińskiego", " 4.6 Wielokąty Sierpińskiego W pierwszym rozdziale pokazaliśmy fraktale zbudowane z wielokątów foremnych o dwóch (kurz Cantora), trzech (trójkąt Sierpińskiego) i czterech (dywan Sierpińskiego) bokach. Okazuje się, że można skonstruować fraktal w oparciu o dowolny wielokąt foremny. Niech \\(n\\) oznacza liczbę boków wielokąta. Fraktal będziemy konstruować, bazując na \\(n\\) transformacjach, z których każda będzie przeskalowaniem oraz przesunięciem. Dla \\(n\\)-kąta współczynnik skalujący opisany jest wzorem: \\[ r_n = \\frac{1}{{2 \\; \\left( {1 + \\sum\\limits_{k = 1}^{\\left\\lfloor {n/4} \\right\\rfloor } {\\cos \\left( {\\frac{{2\\pi k}}{n}} \\right)} } \\right)}}, \\] gdzie \\(\\left\\lfloor {n/4} \\right\\rfloor\\) to podłoga z \\(n/4\\), czyli największa liczba naturalna nie większa od \\(n/4\\). Przeskalowane figury należy przesunąć w boki wielokąta foremnego, gdzie parametry przesunięcia dla \\(k\\)-tej transformacji wyznaczyć można ze wzoru: \\[ (1-r_n) \\left[ {\\begin{array}{*{20}{c}} { \\cos \\left( {\\frac{{2\\pi k}}{n}} \\right)} \\\\ { \\sin \\left( {\\frac{{2\\pi k}}{n}} \\right)} \\\\ \\end{array}} \\right]. \\] Przykładowo, budując fraktal oparty na pięciokącie foremnym, należy skorzystać z pięciu transformacji. Każda skaluje figurę o: \\[ r_5 = \\left( 2 + 2\\cos\\left(\\frac{2\\pi}{5}\\right) \\right)^{-1} \\approx 0,381966 \\] i przesuwa o (dla k = 1, …, 5): \\[ (1-r_5)\\left[ {\\begin{array}{*{20}{c}} { \\cos \\left( {2\\pi k / 5} \\right)} \\\\ { \\sin \\left( {2\\pi k / 5} \\right)} \\\\ \\end{array}} \\right]. \\] Przykłady fraktali dla \\(n=4; 5; 6; 8\\) znajdują się na marginesie. Eksperymentując ze współczynnikiem skalowania oraz z kolorowaniem poszczególnych punktów, możemy otrzymać bardzo fantazyjne wzory. Na marginesie pokazany jest pięciobok Sierpińskiego ze współczynnikiem skalującym 0,4 w którym kolory punktów zależą od zastosowanej transformacji. "],["smoki.html", "4.7 Smoki", " 4.7 Smoki W drugim rozdziale poznaliśmy smoka Heighwaya i drzewo pitagorejskie. Okazuje się, że oba te fraktale należą do bogatszej rodziny, którą można sparametryzować jedną liczbą. Dla każdego \\(T \\in [0,1]\\) można określić taką parę. \\[ f_1(x, y) = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} \\cos(\\pi/4) &amp; -\\sin(\\pi/4) \\\\ \\sin(\\pi/4) &amp; \\cos(\\pi/4) \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\] \\[ f_2(x, y) = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} \\cos\\left(\\frac 34 \\pi - \\frac{T}2 \\pi\\right) &amp; -\\sin\\left(\\frac 34 \\pi - \\frac{T}2 \\pi\\right) \\\\ \\sin\\left(\\frac 34 \\pi - \\frac{T}2 \\pi\\right) &amp; \\cos\\left(\\frac 34 \\pi - \\frac{T}2 \\pi\\right) \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} 1 - T/2 \\\\ T/2 \\end{bmatrix} \\] Poniżej pokazano sześć fraktali z tej rodziny. "],["sky-is-the-limit.html", "4.8 Sky is the limit", " 4.8 Sky is the limit Liczba fraktali, nawet tych zbudowanych z dwóch transformacji, jest dosłownie nieskończona. Warto z nimi eksperymentować! \\[ f_1(x, y) = \\begin{bmatrix} 0,202 &amp; -0,805 &amp; -0,373 \\\\ -0,689 &amp; -0,342 &amp; -0,653 \\end{bmatrix} [x \\ y \\ 1]^T \\] \\[ f_2(x, y) = \\begin{bmatrix} 0,138 &amp; 0,665 &amp; 0,66 \\\\ -0,502 &amp; -0,222 &amp; -0,277 \\end{bmatrix} [x \\ y \\ 1]^T \\] "],["bibliografia.html", "Bibliografia", " Bibliografia "]]
